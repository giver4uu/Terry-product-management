# Opportunity: 평가 기준 일관성

**식별일:** 2025-11-16
**출처:** 보리 인터뷰 (snapshot-borry-2025-11-16.md)
**우선순위:** High
**임팩트 영역:** 채용 품질, 의사결정 확신도, 법적 리스크 감소

---

## 고객 문제 (Customer Problem)

### 구체적 상황
면접관들이 **같은 평가 항목(예: 커뮤니케이션)을 각자 다른 기준으로 평가**하여, 점수의 의미가 불명확하고 최종 의사결정에 확신을 갖지 못합니다.

### 실제 사례
**시니어 백엔드 개발자 면접 평가:**
- **같은 "커뮤니케이션" 항목, 3명의 면접관, 3가지 다른 점수:**
  - 제임스 (개발 리드): **5점** - "기술 내용을 명확하게 설명했다"
  - 마케팅 팀장: **3점** - "비개발자에게 설명하는 능력이 부족하다"
  - 다른 개발자: **4점** - "질문에 잘 답변했다"

- **문제의 본질:**
  - 각자 "커뮤니케이션"의 정의가 다름 (기술 설명 vs 비개발자 소통 vs 응답 능력)
  - 루브릭에 점수(1-5)만 있고, 각 점수가 의미하는 구체적 기준이 없음
  - 평가 회의에서 1시간 동안 논쟁했으나 명확한 근거 없이 선임자 의견 따름

### 고객의 목소리
> "면접관이 3명이었어요. 모두 '커뮤니케이션'을 평가 항목으로 뽑았는데, 결과가 완전히 달랐어요."

> "각자 '5점'이 뭔지, '3점'이 뭔지에 대한 정의가 전혀 없으니까 논의가 계속 엇나가더라고요."

> "이게 맞는 결정인지 확신이 없었어요. 루브릭에는 점수만 있고, 각 점수가 구체적으로 뭘 의미하는지 명확한 기준이 없으니까요."

> "솔직히... 무력감이 들어요. 채용이 회사의 미래를 좌우하는데, 매번 제대로 하고 있는지 확신이 없어요."

---

## 현재 해결 방법과 한계

### 현재 시도한 방법
1. **엑셀 기반 평가표 사용**
   - 평가 항목과 1-5점 척도 제공
   - 결과: 점수만 있고 기준 없음
   - 한계: 면접관마다 해석이 다름

2. **사전 면접관 회의**
   - 면접 전 평가 항목 합의
   - 결과: 항목명만 합의하고 구체적 기준은 논의 안 함
   - 한계: 실제 평가 시 각자 기준대로 진행

3. **평가 후 조율 회의**
   - 점수 차이 나면 회의로 조율
   - 결과: 1시간 논쟁 후 선임자 의견 따름
   - 한계: 근거 없는 의사결정, 확신 부족

### 왜 실패했는가?
- **암묵적 기준의 한계:** 각 면접관의 머릿속에만 존재하는 기준은 공유 불가
- **점수의 모호성:** "3점"이 중간인지, 부족한 건지, 맥락에 따라 달라짐
- **사후 조율의 비효율:** 이미 평가 후 조율은 편향과 논쟁만 발생

---

## 온톨로지 기반 솔루션 가능성

### HR 온톨로지가 해결할 수 있는 것

**1. 평가 항목의 구체적 정의**
```
커뮤니케이션 (Communication)
├─ 정의: "정보를 명확하고 효과적으로 전달하고 수신하는 능력"
├─ 하위 역량:
│  ├─ 기술적 설명 능력 (Technical Explanation)
│  ├─ 비기술자 대상 소통 (Non-technical Communication)
│  └─ 경청 및 이해 (Active Listening)
└─ 평가 맥락: 시니어 개발자는 "기술적 설명 능력" + "비기술자 대상 소통" 모두 필요
```

**2. 레벨별 루브릭 정의 (시니어 백엔드 개발자 예시)**
```
커뮤니케이션 - 기술적 설명 능력
├─ 5점 (탁월): 복잡한 기술 개념을 구조화하여 설명, 질문 예상하고 선제적 답변
├─ 4점 (우수): 기술 개념을 명확히 설명, 질문에 적절히 답변
├─ 3점 (보통): 기본적 설명 가능하나 깊이 부족, 질문에 일부만 답변
├─ 2점 (부족): 설명이 불명확하거나 논리 비약, 질문 이해 어려움
└─ 1점 (매우 부족): 의사소통에 심각한 장애

커뮤니케이션 - 비기술자 대상 소통
├─ 5점 (탁월): 기술 용어 없이 명확한 비유로 설명, 청중 수준 맞춤
├─ 4점 (우수): 기술 개념을 쉬운 언어로 번역 가능
├─ 3점 (보통): 노력하나 여전히 전문 용어 사용
├─ 2점 (부족): 비기술자 관점 전환 어려움
└─ 1점 (매우 부족): 기술자 관점에서만 소통
```

**3. 평가 가이드 및 예시**
```
커뮤니케이션 - 기술적 설명 능력 - 5점 예시:
- 행동: "아키텍처를 계층별로 나누어 설명하고, 각 레이어의 책임과 상호작용을 다이어그램으로 표현"
- 인용: "먼저 전체 구조를 말씀드리면... 이 부분에서 궁금하실 수 있는데..."
- 관찰: 질문하기 전에 예상 질문에 대한 답변을 포함
```

**4. 포지션별 가중치 정의**
```
시니어 백엔드 개발자
├─ 커뮤니케이션 - 기술적 설명 능력: 필수 (최소 4점)
└─ 커뮤니케이션 - 비기술자 대상 소통: 선호 (3점 이상 권장)

프론트엔드 팀 리드
├─ 커뮤니케이션 - 기술적 설명 능력: 필수 (최소 4점)
└─ 커뮤니케이션 - 비기술자 대상 소통: 필수 (최소 4점) ← 디자이너/PM 협업 필수
```

### 핵심 가치 제안
- **명확성**: 각 점수가 정확히 무엇을 의미하는지 구체적 행동으로 정의
- **일관성**: 모든 면접관이 같은 기준으로 평가
- **맥락화**: 포지션별로 어떤 하위 역량이 중요한지 명시
- **학습 가능**: 신입 면접관도 가이드 보고 일관되게 평가 가능

---

## 예상 임팩트

### 정량적 임팩트
- **평가 조율 회의 시간 단축:** 1시간 → 15분 (75% 감소)
  - 근거: 명확한 루브릭으로 점수 의미 합의 필요 없음
- **평가자 간 신뢰도 향상:** Inter-rater reliability 20%p 증가
  - 근거: 같은 기준 사용 시 평가 일치도 상승
- **법적 리스크 감소:** 차별적 평가 주장 50% 감소
  - 근거: 객관적이고 문서화된 기준으로 방어 가능

### 정성적 임팩트
- **의사결정 확신도 향상:**
  - "이게 맞나?" 불안감 해소
  - 데이터 기반 명확한 근거로 결정
- **채용 품질 향상:**
  - 일관된 기준으로 우수 후보자 선별
  - 개인 편향 감소
- **신입 면접관 온보딩 가속화:**
  - 루브릭 가이드로 빠른 학습
  - 제임스 같은 전문가 의존도 감소
- **조직 공정성 강화:**
  - 투명한 평가 기준으로 신뢰 구축
  - 지원자 경험 개선 (왜 떨어졌는지 피드백 가능)

### 2차 효과
- **성과 관리 연계:** 채용 평가 기준을 성과 리뷰에도 활용
- **교육 니즈 파악:** 평가 데이터로 조직 역량 갭 분석
- **지속적 개선:** 합격자 성과 추적으로 루브릭 정교화

---

## 가정 (Assumptions)

### 검증 필요한 가정
1. **루브릭 수용성:**
   - 가정: 면접관들이 상세한 루브릭을 참고하며 평가할 의향 있음
   - 리스크: "너무 복잡하다", "내 판단 제약한다" 반발
   - 검증 방법: 파일럿 면접 5회 실행 후 면접관 피드백

2. **루브릭 정확도:**
   - 가정: 5단계 루브릭이 실제 후보자 능력 차이를 변별 가능
   - 리스크: 모든 후보자가 3-4점에 몰림
   - 검증 방법: 과거 평가 데이터로 시뮬레이션

3. **유지보수 부담:**
   - 가정: 루브릭 업데이트를 분기 1회로 관리 가능
   - 리스크: 직무 변화로 매주 수정 필요
   - 검증 방법: 3개월 사용 후 변경 빈도 측정

4. **문화적 저항:**
   - 가정: 정량 평가에 대한 조직 거부감 없음
   - 리스크: "사람을 숫자로 평가한다" 반발
   - 검증 방법: 경영진 및 팀 리더 사전 인터뷰

---

## 경쟁 솔루션 분석

### 기존 시장 솔루션
1. **일반 평가표 템플릿:**
   - 제공: 평가 항목과 점수 척도
   - 한계: 점수 기준 정의 없음
   - 차별점: 온톨로지 기반 구체적 행동 루브릭

2. **역량 기반 면접 (Competency-based Interview):**
   - 제공: 역량 정의와 질문 가이드
   - 한계: 평가 기준은 여전히 주관적
   - 차별점: 정량 루브릭과 정성 가이드 결합

3. **구조화된 면접 도구 (BrightHire, GoodTime 등):**
   - 제공: 면접 가이드 및 기록 자동화
   - 한계: 평가 기준은 회사가 직접 정의해야 함
   - 차별점: HR 온톨로지로 업계 베스트 프랙티스 루브릭 제공

---

## 다음 단계

### 즉시 실행 (Now)
- [ ] 보리님의 실제 평가표 수집 (과거 5회 채용)
- [ ] 면접관 3명 (제임스 포함) 인터뷰: "커뮤니케이션 5점"의 의미 정의 요청
- [ ] "커뮤니케이션" 역량에 대한 프로토타입 루브릭 작성

### 단기 (Next 2 weeks)
- [ ] 시니어 백엔드 개발자 역할에 대한 전체 루브릭 세트 개발
- [ ] 루브릭 초안을 제임스에게 검토 요청
- [ ] 온톨로지 스키마에 루브릭 데이터 모델링

### 중기 (Next 1-2 months)
- [ ] 다음 채용에서 새 루브릭 파일럿 테스트
- [ ] 평가자 간 신뢰도 측정 (기존 vs 신규 루브릭 비교)
- [ ] 면접관 만족도 및 개선 피드백 수집

---

## 관련 Opportunities
- [01-skill-standardization.md](./01-skill-standardization.md) - 스킬/역량 표준화 체계 (평가 항목 정의에 필요)
- [03-knowledge-reuse.md](./03-knowledge-reuse.md) - 채용 지식 재사용 (루브릭 재사용)
- [04-cross-team-sharing.md](./04-cross-team-sharing.md) - 팀 간 노하우 공유 (우수 평가 사례 공유)

---

## 참고 자료
- 인터뷰 스냅샷: `user-interviews/snapshots/snapshot-borry-2025-11-16.md`
- 인터뷰 원본: `user-interviews/transcripts/transcript-borry-2025-11-16.md`
- Google's Structured Interview Guide: https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/
- SHRM Interview Guide: https://www.shrm.org/resourcesandtools/tools-and-samples/toolkits/pages/conductingeffectiveinterviews.aspx
