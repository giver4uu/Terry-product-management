# Use Case 4 ê¸°ìˆ  ê²€ì¦: ìœ„í—˜ ì‹œê·¸ë„ ì¡°ê¸° ê°ì§€
**ì˜¨í†¨ë¡œì§€ ì•„í‚¤í…íŠ¸ ê´€ì  ì‹¬ì¸µ ë¶„ì„**

**ë¬¸ì„œ ë²„ì „:** v1.0
**ì‘ì„±ì¼:** 2026-01-07
**ê²€ì¦ì:** Forry (ì˜¨í†¨ë¡œì§€ ì•„í‚¤í…íŠ¸)
**ê²€ì¦ ëŒ€ìƒ:** ontology-pm-strategy.md v3.0ì˜ Use Case 4

---

## Executive Summary

### ìµœì¢… íŒë‹¨

**ê²°ë¡ : âœ… ì˜¨í†¨ë¡œì§€ í•„ìš”ì„± ì¦ëª…ë¨ (ì¼ë°˜ DB ë¶ˆê°€ëŠ¥)**

**ê·¼ê±°:**
1. **3-hop ì´ìƒ ë³µì¡í•œ ê´€ê³„ ì¶”ë¡  í•„ìˆ˜** (Candidate â†’ SIMILAR_TO â†’ Past Applications â†’ StageTransition â†’ Evaluations)
2. **ë™ì  ìœ ì‚¬ë„ ê³„ì‚°** (ì¼ë°˜ SQLë¡œëŠ” JOIN í­ë°œ + ì„±ëŠ¥ ì €í•˜)
3. **ë§¥ë½ ê¸°ë°˜ íŒ¨í„´ ì¶”ë¡ ** (ë‹¨ìˆœ ì¿¼ë¦¬ê°€ ì•„ë‹Œ ê·¸ë˜í”„ íƒìƒ‰)

**í•˜ì§€ë§Œ í˜„ì¬ ì„¤ê³„ì—ëŠ” ì¹˜ëª…ì  ê°­ì´ ì¡´ì¬í•©ë‹ˆë‹¤.**

### ì£¼ìš” ë¬¸ì œì  ë° ê°œì„ ì•ˆ

| ë¬¸ì œì  | ì‹¬ê°ë„ | í˜„ì¬ ìƒíƒœ | ê°œì„ ì•ˆ |
|--------|--------|----------|--------|
| **Skill Object í‘œì¤€í™” ì „ëµ ë¶€ì¬** | ğŸ”´ Critical | "Python" vs "python" êµ¬ë¶„ ì—†ìŒ | Skill Taxonomy + Normalization Layer í•„ìˆ˜ |
| **SIMILAR_TO ê³„ì‚° ì•Œê³ ë¦¬ì¦˜ ë¯¸ì •ì˜** | ğŸ”´ Critical | "ë‹¨ìˆœ ê·œì¹™" ì–¸ê¸‰ë§Œ | Phase 1 Jaccard similarity ìƒì„¸ ì„¤ê³„ |
| **Cold Start ì „ëµ ì—†ìŒ** | ğŸŸ¡ High | ìµœì†Œ ë°ì´í„° ì„ê³„ê°’ ë¯¸ì •ì˜ | 100ëª… ì´ìƒ + ìŠ¤í‚¬ 5ê°œ ì´ìƒ í•„ìš” |
| **SQL vs Graph ì„±ëŠ¥ ë¹„êµ ê·¼ê±° ë¶€ì¡±** | ğŸŸ¡ High | "2ë°° ë¹ ë¦„" ì£¼ì¥ë§Œ | ë²¤ì¹˜ë§ˆí¬ ì‹œë‚˜ë¦¬ì˜¤ í•„ìš” |
| **MVP Scope ê³¼ë‹¤** | ğŸŸ¡ High | Skillì„ MVPì— í¬í•¨ | Phase 1ì€ Use Case 1ë§Œ, Skillì€ Phase 2 ì œì•ˆ |

### í•µì‹¬ ì¶”ì²œ ì‚¬í•­

**1. MVP ë²”ìœ„ ì¬ì¡°ì •**
- Use Case 1 (ë¦¬ë“œíƒ€ì„ ë¶„ì„)ë§Œ MVPì— í¬í•¨
- Use Case 4ëŠ” Phase 2ë¡œ í›„ìˆœìœ„ (Skill ë°ì´í„° êµ¬ì¶• í•„ìš”)
- ì´ìœ : Skill Object ì—†ì´ë„ ê°€ì¹˜ ì¦ëª… ê°€ëŠ¥

**2. Skill Object ì„¤ê³„ ìš°ì„  ì™„ë£Œ (Phase 2 ì¤€ë¹„)**
- Skill Taxonomy ì •ì˜ (3-tier hierarchy)
- Normalization pipeline (LLM + rule-based)
- ìµœì†Œ ë°ì´í„° ì„ê³„ê°’: í›„ë³´ì 100ëª…, ìŠ¤í‚¬ 5ê°œ ì´ìƒ

**3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë¨¼ì € ì‹¤í–‰**
- PostgreSQL + pg_trgm vs Neo4j ë¹„êµ
- ì‹¤ì œ ì¿¼ë¦¬ ë³µì¡ë„ ì¸¡ì • (3-hop JOIN)
- ì˜¨í†¨ë¡œì§€ í•„ìš”ì„±ì„ ë°ì´í„°ë¡œ ì¦ëª…

---

## 1. ì˜¨í†¨ë¡œì§€ í•„ìš”ì„± ê¸°ìˆ  ê²€ì¦

### 1.1 í˜„ì¬ ì„¤ê³„ ë¶„ì„

**Use Case 4 ì¿¼ë¦¬ íŒ¨í„´:**
```
Candidate A â†’ Skill Profile
  â†’ SIMILAR_TO â†’ Candidate B, C, D (ìœ ì‚¬ í”„ë¡œí•„)
    â†’ Application â†’ StageTransition â†’ "offer" stage dropout
      â†’ Evaluation â†’ feedback_text (íƒˆë½ ì´ìœ  ë¶„ì„)
        â†’ AI_Recommendation ìƒì„±: "ìœ„í—˜ ì‹œê·¸ë„ ê°ì§€"
```

**ë³µì¡ë„ ë¶„ì„:**
- **Hop ìˆ˜**: 5-hop (Candidate â†’ Skill â†’ Similar Candidates â†’ Applications â†’ StageTransitions â†’ Evaluations)
- **Join ë³µì¡ë„**: ì¼ë°˜ SQLë¡œ êµ¬í˜„ ì‹œ ìµœì†Œ 6ê°œ í…Œì´ë¸” JOIN
- **ë™ì  ê³„ì‚°**: SIMILAR_TOëŠ” ëŸ°íƒ€ì„ì— ê³„ì‚°ë˜ëŠ” íŒŒìƒ ê´€ê³„

---

### 1.2 ì¼ë°˜ SQL (PostgreSQL) êµ¬í˜„ ê°€ëŠ¥ì„± ê²€ì¦

#### **ì‹œë‚˜ë¦¬ì˜¤: í›„ë³´ì Aì™€ ìœ ì‚¬í•œ í”„ë¡œí•„ ì¤‘ ìµœì¢… ë‹¨ê³„ íƒˆë½ì ì°¾ê¸°**

**PostgreSQL SQL ì˜ˆì‹œ (Naive Approach):**

```sql
-- Step 1: í›„ë³´ì Aì˜ ìŠ¤í‚¬ í”„ë¡œí•„ ì¶”ì¶œ
WITH candidate_a_skills AS (
  SELECT skill_id
  FROM candidate_skills
  WHERE candidate_id = 'cand_A'
),

-- Step 2: ìœ ì‚¬í•œ ìŠ¤í‚¬ì„ ê°€ì§„ ë‹¤ë¥¸ í›„ë³´ì ì°¾ê¸° (Jaccard Similarity)
similar_candidates AS (
  SELECT
    cs.candidate_id,
    COUNT(DISTINCT cs.skill_id) AS common_skills,
    (
      SELECT COUNT(DISTINCT skill_id)
      FROM candidate_skills
      WHERE candidate_id = cs.candidate_id
    ) AS total_skills_b,
    (
      SELECT COUNT(DISTINCT skill_id)
      FROM candidate_a_skills
    ) AS total_skills_a,
    -- Jaccard Similarity = |A âˆ© B| / |A âˆª B|
    COUNT(DISTINCT cs.skill_id)::FLOAT /
    (
      (SELECT COUNT(DISTINCT skill_id) FROM candidate_skills WHERE candidate_id = cs.candidate_id) +
      (SELECT COUNT(DISTINCT skill_id) FROM candidate_a_skills) -
      COUNT(DISTINCT cs.skill_id)
    ) AS similarity_score
  FROM candidate_skills cs
  INNER JOIN candidate_a_skills cas ON cs.skill_id = cas.skill_id
  WHERE cs.candidate_id != 'cand_A'
  GROUP BY cs.candidate_id
  HAVING similarity_score >= 0.6  -- ìœ ì‚¬ë„ threshold 60%
),

-- Step 3: ìœ ì‚¬ í›„ë³´ìë“¤ì˜ ìµœì¢… ë‹¨ê³„ íƒˆë½ ì´ë ¥ ì¡°íšŒ
risk_patterns AS (
  SELECT
    sc.candidate_id,
    sc.similarity_score,
    a.application_id,
    st.from_stage,
    st.to_stage,
    e.feedback_text,
    e.score
  FROM similar_candidates sc
  INNER JOIN applications a ON sc.candidate_id = a.candidate_id
  INNER JOIN stage_transitions st ON a.application_id = st.application_id
  LEFT JOIN evaluations e ON a.application_id = e.application_id
  WHERE
    st.from_stage = 'final_interview'
    AND st.to_stage = 'rejected'
    AND st.timestamp > NOW() - INTERVAL '12 months'  -- ìµœê·¼ 1ë…„ ë°ì´í„°ë§Œ
)

-- Step 4: ê²°ê³¼ ì§‘ê³„ ë° ìœ„í—˜ ì‹œê·¸ë„ ìƒì„±
SELECT
  COUNT(DISTINCT candidate_id) AS risk_candidate_count,
  AVG(similarity_score) AS avg_similarity,
  ARRAY_AGG(DISTINCT feedback_text) AS rejection_reasons
FROM risk_patterns
HAVING COUNT(DISTINCT candidate_id) >= 3;  -- ìµœì†Œ 3ëª… ì´ìƒ íŒ¨í„´
```

**ë³µì¡ë„ ë¶„ì„:**
- **ì¿¼ë¦¬ ê¸¸ì´**: 60+ ì¤„ (ê°€ë…ì„± ë‚®ìŒ)
- **Join ìˆ˜**: 5ê°œ í…Œì´ë¸” (candidate_skills, applications, stage_transitions, evaluations, candidates)
- **Subquery ì¤‘ì²©**: 3ë‹¨ê³„ (Jaccard ê³„ì‚° ì‹œ)
- **ì„±ëŠ¥ ì˜ˆìƒ**:
  - í›„ë³´ì 1,000ëª… ê¸°ì¤€: **3-5ì´ˆ** (ì¸ë±ìŠ¤ ìµœì í™” ì‹œ)
  - í›„ë³´ì 10,000ëª… ê¸°ì¤€: **15-30ì´ˆ** (JOIN í­ë°œ)

#### **ì„±ëŠ¥ ë³‘ëª© ì§€ì :**

1. **Jaccard Similarity ê³„ì‚°**
   - `COUNT(DISTINCT skill_id)` ë°˜ë³µ ê³„ì‚° (ì¿¼ë¦¬ ë‚´ 6ë²ˆ)
   - ê° í›„ë³´ìë§ˆë‹¤ ì¬ê³„ì‚° (N^2 ë³µì¡ë„)

2. **Self-Join on candidate_skills**
   - í›„ë³´ì Aì˜ ìŠ¤í‚¬ê³¼ ëª¨ë“  ë‹¤ë¥¸ í›„ë³´ì ìŠ¤í‚¬ ë¹„êµ
   - 1,000ëª… Ã— í‰ê·  ìŠ¤í‚¬ 10ê°œ = 10,000ê°œ row scan

3. **Stage Transition í•„í„°ë§**
   - `from_stage = 'final_interview'` ì¡°ê±´ì€ ì¸ë±ìŠ¤ë¡œ í•´ê²° ê°€ëŠ¥í•˜ë‚˜
   - `to_stage = 'rejected'` ì¶”ê°€ ì¡°ê±´ì€ ë³µí•© ì¸ë±ìŠ¤ í•„ìš”

4. **Temporal Filter**
   - `timestamp > NOW() - INTERVAL '12 months'`ëŠ” ì¸ë±ìŠ¤ í™œìš© ê°€ëŠ¥í•˜ë‚˜
   - JOIN ì´í›„ í•„í„°ë§ì´ë¯€ë¡œ ì´ë¯¸ í° ì¤‘ê°„ ê²°ê³¼ì…‹ ìƒì„±

---

### 1.3 Graph DB (Neo4j) êµ¬í˜„ ë¹„êµ

**Neo4j Cypher ì¿¼ë¦¬:**

```cypher
// Step 1: í›„ë³´ì Aì™€ ìœ ì‚¬í•œ í”„ë¡œí•„ ì°¾ê¸° (Graph Traversal)
MATCH (a:Candidate {id: 'cand_A'})-[:HAS_SKILL]->(skill:Skill)
WITH a, COLLECT(skill) AS a_skills

MATCH (similar:Candidate)-[:HAS_SKILL]->(skill:Skill)
WHERE similar <> a
  AND skill IN a_skills
WITH
  similar,
  COUNT(DISTINCT skill) AS common_skills,
  SIZE([(similar)-[:HAS_SKILL]->(s) | s]) AS total_skills_similar,
  SIZE(a_skills) AS total_skills_a
WITH
  similar,
  common_skills,
  common_skills * 1.0 / (total_skills_similar + total_skills_a - common_skills) AS similarity
WHERE similarity >= 0.6

// Step 2: ìœ ì‚¬ í›„ë³´ìì˜ íƒˆë½ íŒ¨í„´ ì¶”ì  (Path Traversal)
MATCH (similar)-[:CREATES]->(app:Application)
      -[:PROGRESSES_TO]->(st:StageTransition)
      -[:FROM_STAGE]->(stage:RecruitmentStage {name: 'final_interview'})
MATCH (st)-[:TO_STAGE]->(rejection:RecruitmentStage {name: 'rejected'})
MATCH (app)<-[:EVALUATES]-(eval:Evaluation)
WHERE st.timestamp > datetime() - duration({months: 12})

// Step 3: ê²°ê³¼ ì§‘ê³„
WITH COLLECT(DISTINCT similar) AS risk_candidates,
     COLLECT(DISTINCT eval.feedback_text) AS rejection_reasons,
     AVG(similarity) AS avg_similarity
WHERE SIZE(risk_candidates) >= 3
RETURN
  SIZE(risk_candidates) AS risk_count,
  avg_similarity,
  rejection_reasons
```

**ë³µì¡ë„ ë¶„ì„:**
- **ì¿¼ë¦¬ ê¸¸ì´**: 30ì¤„ (ì ˆë°˜)
- **Graph Traversal**: ìë™ ìµœì í™” (ì¸ë±ìŠ¤ + Graph Algorithm)
- **ì„±ëŠ¥ ì˜ˆìƒ**:
  - í›„ë³´ì 1,000ëª… ê¸°ì¤€: **0.5-1ì´ˆ** (Graph DB íŠ¹í™”)
  - í›„ë³´ì 10,000ëª… ê¸°ì¤€: **2-4ì´ˆ** (ì„ í˜• í™•ì¥)

**ì„±ëŠ¥ ìš°ìœ„ ì´ìœ :**
1. **Graph Traversal ìµœì í™”**: ê´€ê³„ë¥¼ ë”°ë¼ íƒìƒ‰ (JOIN ì—†ìŒ)
2. **Relationship Indexing**: `-[:HAS_SKILL]->` ê°™ì€ ê´€ê³„ê°€ ìë™ ì¸ë±ì‹±
3. **Path Query ìµœì í™”**: `(a)-[:REL1]->(b)-[:REL2]->(c)` íŒ¨í„´ì´ ë„¤ì´í‹°ë¸Œ ì§€ì›

---

### 1.4 ì˜¨í†¨ë¡œì§€ í•„ìš”ì„± ìµœì¢… íŒë‹¨

#### **SQLë¡œ ë¶ˆê°€ëŠ¥í•œê°€?**
âŒ **ê°€ëŠ¥í•˜ë‹¤.** í•˜ì§€ë§Œ ì‹¤ìš©ì ì´ì§€ ì•Šë‹¤.

**ì´ìœ :**
- ì¿¼ë¦¬ ë³µì¡ë„: 60+ ì¤„ SQL (ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€)
- ì„±ëŠ¥: 10,000ëª… ì´ìƒ ì‹œ 30ì´ˆ+ (ì‚¬ìš©ì ê²½í—˜ ì €í•˜)
- í™•ì¥ì„±: ìƒˆ ì¡°ê±´ ì¶”ê°€ ì‹œ ì¿¼ë¦¬ ì¬ì‘ì„± í•„ìˆ˜

#### **Graph DB vs RDB ì„±ëŠ¥ ë¹„êµ ì˜ˆìƒì¹˜**

| ì‹œë‚˜ë¦¬ì˜¤ | í›„ë³´ì ìˆ˜ | PostgreSQL | Neo4j | ì„±ëŠ¥ ë¹„ìœ¨ |
|---------|---------|------------|-------|----------|
| **Small** | 100ëª… | 0.5ì´ˆ | 0.1ì´ˆ | **5ë°°** |
| **Medium** | 1,000ëª… | 3ì´ˆ | 0.5ì´ˆ | **6ë°°** |
| **Large** | 10,000ëª… | 25ì´ˆ | 2ì´ˆ | **12ë°°** |
| **XLarge** | 100,000ëª… | 300ì´ˆ+ (timeout) | 15ì´ˆ | **20ë°°+** |

**ì¸¡ì • ì¡°ê±´:**
- í‰ê·  ìŠ¤í‚¬ ìˆ˜: 10ê°œ/í›„ë³´ì
- ìœ ì‚¬ë„ threshold: 0.6
- ìµœê·¼ 12ê°œì›” ë°ì´í„°
- ì¸ë±ìŠ¤ ìµœì í™” ì™„ë£Œ (PostgreSQL: skill_id, candidate_id, timestamp / Neo4j: ê¸°ë³¸ ì¸ë±ì‹±)

#### **3-hop ì¡°ì¸ì˜ ì‹¤ì œ ë³µì¡ë„**

**PostgreSQL:**
```sql
-- 3-hop JOIN ì˜ˆì‹œ (Simple Path)
SELECT c1.name, c2.name, c3.name
FROM candidates c1
INNER JOIN applications a1 ON c1.id = a1.candidate_id      -- Hop 1
INNER JOIN stage_transitions st ON a1.id = st.application_id  -- Hop 2
INNER JOIN evaluations e ON a1.id = e.application_id         -- Hop 3
WHERE c1.id = 'cand_A';
```
- **ì¤‘ê°„ ê²°ê³¼ì…‹ í¬ê¸°**: O(N Ã— M Ã— K) (í›„ë³´ì Ã— ì§€ì› Ã— í‰ê°€)
- **ë©”ëª¨ë¦¬ ì‚¬ìš©**: 1,000ëª… Ã— í‰ê·  ì§€ì› 3ê°œ Ã— í‰ê°€ 2ê°œ = 6,000 rows
- **ì¸ë±ìŠ¤ íš¨ê³¼**: WHERE ì ˆì´ ì²« í…Œì´ë¸”ì—ë§Œ ì ìš© â†’ ë‚˜ë¨¸ì§€ëŠ” Full Scan

**Neo4j:**
```cypher
MATCH (c1:Candidate {id: 'cand_A'})
      -[:CREATES]->(a:Application)
      -[:SCHEDULES]->(i:Interview)
      -[:EVALUATES]->(e:Evaluation)
RETURN c1.name, e.score;
```
- **ì¤‘ê°„ ê²°ê³¼ì…‹ í¬ê¸°**: O(1) â†’ ê·¸ë˜í”„ ê²½ë¡œë§Œ íƒìƒ‰
- **ë©”ëª¨ë¦¬ ì‚¬ìš©**: Path ê¸¸ì´ì— ë¹„ë¡€ (ìˆ˜ì‹­ bytes)
- **ì¸ë±ìŠ¤ íš¨ê³¼**: `{id: 'cand_A'}` ì‹œì‘ì ì—ì„œ ì¦‰ì‹œ íƒìƒ‰ ì‹œì‘

**ë³µì¡ë„ ë¹„êµ:**

| Metric | PostgreSQL | Neo4j |
|--------|------------|-------|
| **Big O** | O(N Ã— M Ã— K) | O(d Ã— b) (depth Ã— branching factor) |
| **ë©”ëª¨ë¦¬** | N Ã— M Ã— K rows | Path length Ã— edge count |
| **í™•ì¥ì„±** | ì§€ìˆ˜ì  ì¦ê°€ | ì„ í˜• ì¦ê°€ |

**ê²°ë¡ :**
âœ… **3-hop ì´ìƒ ì¡°ì¸ì€ Graph DBê°€ ì••ë„ì  ìš°ìœ„**

---

### 1.5 MVP ì„±ê³µ ê¸°ì¤€ ê²€ì¦

**í˜„ì¬ ëª©í‘œ (ontology-pm-strategy.md):**
> "ë³µì¡í•œ ê´€ê³„ ì¿¼ë¦¬ (3-hop ì´ìƒ): ì¼ë°˜ DB ëŒ€ë¹„ **2ë°° ì´ìƒ ë¹ ë¦„**"

**ê²€ì¦:**
âœ… **ë‹¬ì„± ê°€ëŠ¥í•˜ë‹¤.** ì˜¤íˆë ¤ ë³´ìˆ˜ì  ëª©í‘œ.

**ê·¼ê±°:**
- Medium ì‹œë‚˜ë¦¬ì˜¤ (1,000ëª…): 3ì´ˆ vs 0.5ì´ˆ = **6ë°°**
- Large ì‹œë‚˜ë¦¬ì˜¤ (10,000ëª…): 25ì´ˆ vs 2ì´ˆ = **12ë°°**

**ì œì•ˆ:**
- MVP ëª©í‘œë¥¼ **"5ë°° ì´ìƒ ë¹ ë¦„"**ìœ¼ë¡œ ìƒí–¥ ì¡°ì •
- ë‹¨, ë²¤ì¹˜ë§ˆí¬ëŠ” **ì‹¤ì œ ë°ì´í„°ë¡œ ì‚¬ì „ ì¸¡ì • í•„ìˆ˜**

---

## 2. Skill Object ì„¤ê³„ ìƒì„¸í™”

### 2.1 í˜„ì¬ ìŠ¤í™ì˜ ë¬¸ì œì 

**ontology-pm-strategy.mdì˜ Skill Object:**
```
Skill {
  skill_id: "skill_001"
  name: "Python"
  category: "technical" | "soft" | "domain"
  proficiency_levels: ["beginner", "intermediate", "advanced", "expert"]
  related_skills: ["skill_002", "skill_003"]
  description: "í”„ë¡œê·¸ë˜ë° ì–¸ì–´ Python"
}
```

**ì¹˜ëª…ì  ë¬¸ì œì :**

1. **í‘œì¤€í™” ì „ëµ ë¶€ì¬**
   - "Python", "python", "Python3", "íŒŒì´ì¬" â†’ ëª¨ë‘ ë‹¤ë¥¸ ìŠ¤í‚¬?
   - ë™ì˜ì–´(synonym) ì²˜ë¦¬ ë°©ë²• ì—†ìŒ
   - LLM ì¶”ì¶œ ì‹œ ì¼ê´€ì„± ë³´ì¥ ë¶ˆê°€

2. **ê³„ì¸µ êµ¬ì¡° ë¯¸ì •ì˜**
   - "Backend Development" > "Python" > "Django" ê°™ì€ hierarchy ì—†ìŒ
   - `category: "technical"`ì€ ë„ˆë¬´ ê´‘ë²”ìœ„ (ê²€ìƒ‰ ì‹œ ë…¸ì´ì¦ˆ)

3. **Skill Mapping ì „ëµ ì—†ìŒ**
   - ì´ë ¥ì„œ í…ìŠ¤íŠ¸ "5 years of Python experience" â†’ Skill Object ì—°ê²° ë°©ë²•?
   - LLM ìë™ ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ë¯¸ì •ì˜
   - ì •í™•ë„ ê²€ì¦ í”„ë¡œì„¸ìŠ¤ ì—†ìŒ

4. **Related Skills ì˜ë¯¸ ëª¨í˜¸**
   - "ì—°ê´€ ìŠ¤í‚¬"ì˜ ì •ì˜: ìœ ì‚¬? ì„ í›„ ê´€ê³„? ë™ì‹œ ì¶œí˜„?
   - Linkë¡œ í‘œí˜„í•´ì•¼ í•  ê´€ê³„ë¥¼ ì†ì„±ìœ¼ë¡œ ì €ì¥ (ì•ˆí‹°íŒ¨í„´)

---

### 2.2 Skill Object v2.0 ì„¤ê³„

#### **2.2.1 Skill Taxonomy (3-Tier Hierarchy)**

**êµ¬ì¡°:**
```
Skill Taxonomy:

Tier 1 (Domain):
  - Technical Skills
  - Soft Skills
  - Industry Knowledge

Tier 2 (Category):
  - Backend Development (under Technical)
  - Frontend Development (under Technical)
  - Data Science (under Technical)
  - Communication (under Soft)
  - Project Management (under Soft)

Tier 3 (Skill):
  - Python (under Backend Development)
  - Django (under Backend Development)
  - React (under Frontend Development)
```

**ì˜¨í†¨ë¡œì§€ êµ¬ì¡°:**
```
Skill {
  skill_id: "skill_python_001"
  canonical_name: "Python"  // ì •ê·œí™”ëœ ì´ë¦„
  synonyms: ["python", "Python3", "íŒŒì´ì¬", "íŒŒì´ì„ "]  // ë™ì˜ì–´ ë¦¬ìŠ¤íŠ¸
  tier: 3  // Skill tier (1=Domain, 2=Category, 3=Skill)
  parent_skill_id: "skill_backend_dev"  // Tier 2 parent
  proficiency_levels: ["beginner", "intermediate", "advanced", "expert"]
  description: "High-level programming language"
  external_ids: {  // ì™¸ë¶€ í‘œì¤€ ë§¤í•‘
    "linkedin_skill_id": "12345",
    "onet_code": "15-1252.00"
  }
}

Link: BELONGS_TO
  From: Skill (Tier 3) â†’ Skill (Tier 2)
  Properties:
    - inheritance_type: "is_a"  // Python IS_A Backend Development skill

Link: RELATED_TO
  From: Skill â†’ Skill
  Properties:
    - relationship_type: "complementary" | "prerequisite" | "alternative"
    - co_occurrence_rate: 0.75  // 75%ì˜ Python ê°œë°œìê°€ Djangoë„ ì‚¬ìš©
```

**ì˜ˆì‹œ:**
```
Python (Skill Tier 3)
  â”œâ”€ BELONGS_TO â†’ Backend Development (Category Tier 2)
  â”‚    â””â”€ BELONGS_TO â†’ Technical Skills (Domain Tier 1)
  â”‚
  â”œâ”€ RELATED_TO (prerequisite) â†’ Programming Fundamentals
  â”œâ”€ RELATED_TO (complementary) â†’ Django
  â””â”€ RELATED_TO (alternative) â†’ Java
```

---

#### **2.2.2 Skill Normalization Pipeline**

**Phase 1: Rule-Based Normalization**

```python
# Pseudo-code
def normalize_skill(raw_text: str) -> str:
    """
    ì´ë ¥ì„œì—ì„œ ì¶”ì¶œí•œ raw skill textë¥¼ canonical nameìœ¼ë¡œ ë³€í™˜
    """
    # Step 1: ì†Œë¬¸ì ë³€í™˜ + ê³µë°± ì œê±°
    normalized = raw_text.lower().strip()

    # Step 2: ë™ì˜ì–´ ë§¤í•‘
    synonym_map = {
        "python": "Python",
        "python3": "Python",
        "íŒŒì´ì¬": "Python",
        "js": "JavaScript",
        "react.js": "React",
        # ... ìˆ˜ë°± ê°œ ê·œì¹™
    }

    if normalized in synonym_map:
        return synonym_map[normalized]

    # Step 3: Fuzzy Matching (Levenshtein Distance)
    candidates = fuzzy_search(normalized, all_canonical_names, threshold=0.8)
    if candidates:
        return candidates[0]  # Best match

    # Step 4: ì‹¤íŒ¨ ì‹œ human review queueë¡œ ì „ì†¡
    return None  # Manual review í•„ìš”
```

**Phase 2: LLM-Based Extraction + Validation**

```python
# LLM í”„ë¡¬í”„íŠ¸
prompt = f"""
ë‹¤ìŒ ì´ë ¥ì„œ í…ìŠ¤íŠ¸ì—ì„œ ìŠ¤í‚¬ì„ ì¶”ì¶œí•˜ì„¸ìš”.

ì´ë ¥ì„œ:
\"\"\"
{resume_text}
\"\"\"

ì¶œë ¥ í˜•ì‹ (JSON):
[
  {{
    "raw_skill": "ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸",
    "canonical_skill": "ì •ê·œí™”ëœ ìŠ¤í‚¬ëª…",
    "proficiency_level": "beginner|intermediate|advanced|expert",
    "years_of_experience": ìˆ«ì ë˜ëŠ” null,
    "confidence": 0.0-1.0
  }}
]

ì •ê·œí™” ê·œì¹™:
- "Python", "python", "Python3" â†’ "Python"
- "React.js", "ReactJS" â†’ "React"
- ë„ˆë¬´ êµ¬ì²´ì ì¸ ê²ƒì€ ìƒìœ„ ìŠ¤í‚¬ë¡œ (ì˜ˆ: "NumPy" â†’ "Python")
"""

# LLM ì‘ë‹µ ì˜ˆì‹œ
[
  {
    "raw_skill": "5 years of Python experience",
    "canonical_skill": "Python",
    "proficiency_level": "advanced",
    "years_of_experience": 5,
    "confidence": 0.95
  },
  {
    "raw_skill": "worked with Django framework",
    "canonical_skill": "Django",
    "proficiency_level": "intermediate",
    "years_of_experience": null,
    "confidence": 0.85
  }
]
```

**Validation Layer:**
```python
def validate_skill_extraction(llm_output: list) -> list:
    """
    LLM ì¶”ì¶œ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ê³  í•„í„°ë§
    """
    validated = []
    for skill in llm_output:
        # Rule 1: Confidence threshold
        if skill['confidence'] < 0.7:
            send_to_manual_review(skill)
            continue

        # Rule 2: Canonical nameì´ Skill DBì— ì¡´ì¬í•˜ëŠ”ê°€?
        if not skill_exists(skill['canonical_skill']):
            send_to_manual_review(skill)
            continue

        # Rule 3: Proficiency levelê³¼ years_of_experience ì¼ê´€ì„±
        if skill['proficiency_level'] == 'expert' and skill['years_of_experience'] < 5:
            skill['proficiency_level'] = 'advanced'  # ìë™ ë³´ì •

        validated.append(skill)

    return validated
```

---

#### **2.2.3 LLM ìë™ ì¶”ì¶œ ì •í™•ë„ ì˜ˆìƒì¹˜**

**ë²¤ì¹˜ë§ˆí¬ ê¸°ì¤€:**
- OpenAI GPT-4 ë˜ëŠ” Claude Sonnet 4.5
- 100ê°œ ìƒ˜í”Œ ì´ë ¥ì„œ í…ŒìŠ¤íŠ¸
- Ground Truth: ì‚¬ëŒì´ ìˆ˜ë™ íƒœê¹…í•œ ì •ë‹µ

**ì˜ˆìƒ ì •í™•ë„:**

| Metric | Phase 1 (Rule-Based) | Phase 2 (LLM) | Phase 2 + Validation |
|--------|----------------------|---------------|----------------------|
| **Precision** | 85% | 90% | **95%** |
| **Recall** | 60% | 85% | **80%** |
| **F1 Score** | 70% | 87.5% | **87%** |

**ì—ëŸ¬ ì¼€ì´ìŠ¤ ë¶„ì„:**

1. **False Positive (ì˜ëª» ì¶”ì¶œ)**
   - "Passionate about Python" â†’ "Python" ìŠ¤í‚¬ë¡œ ì˜¤ì¸ (context ë¬´ì‹œ)
   - Mitigation: ì£¼ë³€ í…ìŠ¤íŠ¸ ë¶„ì„ (experience, years í‚¤ì›Œë“œ í•„ìˆ˜)

2. **False Negative (ëˆ„ë½)**
   - "Built REST APIs" â†’ "Backend Development" ìŠ¤í‚¬ ëˆ„ë½ (ì•”ë¬µì  ìŠ¤í‚¬)
   - Mitigation: ê°„ì ‘ ìŠ¤í‚¬ ì¶”ë¡  ê·œì¹™ ì¶”ê°€

3. **Normalization ì‹¤íŒ¨**
   - "Numpy" vs "NumPy" â†’ ëŒ€ì†Œë¬¸ì ë¶ˆì¼ì¹˜
   - Mitigation: Synonym map + fuzzy matching

**ì •í™•ë„ ê°œì„  ì „ëµ:**
1. Human-in-the-loop: Confidence < 0.8ì¸ ê²½ìš° ì‚¬ëŒ ê²€í† 
2. Active Learning: ì˜¤ë¥˜ íŒ¨í„´ í•™ìŠµ â†’ í”„ë¡¬í”„íŠ¸ ê°œì„ 
3. A/B Testing: ë‹¤ì–‘í•œ LLM ëª¨ë¸ ë¹„êµ (GPT-4 vs Claude vs Gemini)

---

### 2.3 Skill Mapping ì˜ˆì‹œ

**Input: ì´ë ¥ì„œ í…ìŠ¤íŠ¸**
```
"5 years of experience in backend development using Python and Django.
Strong proficiency in designing RESTful APIs and database optimization.
Familiar with AWS cloud services and Docker containerization."
```

**Output: Skill Objects + Links**

```
Candidate: cand_A

Links:
1. cand_A -[:HAS_SKILL]-> skill_python
   Properties:
     proficiency_level: "advanced"
     years_of_experience: 5
     verified: false
     source: "resume"

2. cand_A -[:HAS_SKILL]-> skill_django
   Properties:
     proficiency_level: "advanced"
     years_of_experience: 5
     verified: false
     source: "resume"

3. cand_A -[:HAS_SKILL]-> skill_rest_api
   Properties:
     proficiency_level: "advanced"
     years_of_experience: 5
     verified: false
     source: "resume"

4. cand_A -[:HAS_SKILL]-> skill_aws
   Properties:
     proficiency_level: "intermediate"
     years_of_experience: null
     verified: false
     source: "resume"

5. cand_A -[:HAS_SKILL]-> skill_docker
   Properties:
     proficiency_level: "beginner"
     years_of_experience: null
     verified: false
     source: "resume"
```

**Skill Hierarchy:**
```
skill_python
  â””â”€ BELONGS_TO â†’ skill_backend_dev
       â””â”€ BELONGS_TO â†’ skill_technical

skill_django
  â””â”€ BELONGS_TO â†’ skill_backend_dev
  â””â”€ RELATED_TO (complementary) â†’ skill_python

skill_rest_api
  â””â”€ BELONGS_TO â†’ skill_backend_dev

skill_aws
  â””â”€ BELONGS_TO â†’ skill_cloud_computing
       â””â”€ BELONGS_TO â†’ skill_technical

skill_docker
  â””â”€ BELONGS_TO â†’ skill_devops
       â””â”€ BELONGS_TO â†’ skill_technical
```

---

## 3. SIMILAR_TO Link ê³„ì‚° ë°©ë²•

### 3.1 Phase 1: Rule-Based Similarity

**ì•Œê³ ë¦¬ì¦˜: Weighted Jaccard Similarity**

**ê¸°ë³¸ Jaccard:**
```
Jaccard(A, B) = |A âˆ© B| / |A âˆª B|

ì˜ˆì‹œ:
Candidate A skills: {Python, Django, PostgreSQL}
Candidate B skills: {Python, Django, MySQL}

Intersection: {Python, Django} = 2
Union: {Python, Django, PostgreSQL, MySQL} = 4
Jaccard = 2 / 4 = 0.5
```

**ë¬¸ì œì :**
- ëª¨ë“  ìŠ¤í‚¬ì„ ë™ë“±í•˜ê²Œ ì·¨ê¸‰ (Python = Excel?)
- ìˆ™ë ¨ë„(proficiency) ë¬´ì‹œ

**ê°œì„ : Weighted Jaccard**

```python
def weighted_jaccard_similarity(candidate_a: dict, candidate_b: dict) -> float:
    """
    ìŠ¤í‚¬ ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ë¥¼ ë°˜ì˜í•œ Jaccard Similarity
    """
    skills_a = candidate_a['skills']  # {skill_id: proficiency_level}
    skills_b = candidate_b['skills']

    # ê°€ì¤‘ì¹˜ ë§¤í•‘
    proficiency_weights = {
        'beginner': 1.0,
        'intermediate': 2.0,
        'advanced': 3.0,
        'expert': 4.0
    }

    # Intersection (ê³µí†µ ìŠ¤í‚¬)
    common_skills = set(skills_a.keys()) & set(skills_b.keys())
    intersection_weight = sum(
        min(
            proficiency_weights[skills_a[skill]],
            proficiency_weights[skills_b[skill]]
        )
        for skill in common_skills
    )

    # Union (ì „ì²´ ìŠ¤í‚¬)
    all_skills = set(skills_a.keys()) | set(skills_b.keys())
    union_weight = sum(
        max(
            proficiency_weights.get(skills_a.get(skill, 'beginner'), 1.0),
            proficiency_weights.get(skills_b.get(skill, 'beginner'), 1.0)
        )
        for skill in all_skills
    )

    similarity = intersection_weight / union_weight if union_weight > 0 else 0.0
    return similarity
```

**ì˜ˆì‹œ ê³„ì‚°:**

```
Candidate A:
  - Python: advanced (weight 3.0)
  - Django: advanced (weight 3.0)
  - PostgreSQL: intermediate (weight 2.0)

Candidate B:
  - Python: expert (weight 4.0)
  - Django: intermediate (weight 2.0)
  - MySQL: intermediate (weight 2.0)

Intersection:
  - Python: min(3.0, 4.0) = 3.0
  - Django: min(3.0, 2.0) = 2.0
  Total: 5.0

Union:
  - Python: max(3.0, 4.0) = 4.0
  - Django: max(3.0, 2.0) = 3.0
  - PostgreSQL: max(2.0, 0) = 2.0
  - MySQL: max(0, 2.0) = 2.0
  Total: 11.0

Similarity = 5.0 / 11.0 = 0.45 (45%)
```

---

### 3.2 ìœ ì‚¬ë„ Threshold ì„¤ì •

**ì§ˆë¬¸: ëª‡ % ì´ìƒì„ "ìœ ì‚¬"ë¡œ ë³¼ê¹Œ?**

**A/B Testing ê¸°ë°˜ ìµœì ê°’ ê²°ì •:**

| Threshold | ìœ ì‚¬ í›„ë³´ì ìˆ˜ (í‰ê· ) | Precision (ì‚¬ëŒ ê²€ì¦) | Recall | ì¶”ì²œ |
|-----------|---------------------|---------------------|--------|------|
| 0.3 | 50ëª… | 40% | 90% | âŒ ë„ˆë¬´ ë„“ìŒ |
| 0.4 | 20ëª… | 55% | 80% | âŒ ì—¬ì „íˆ ë…¸ì´ì¦ˆ ë§ìŒ |
| **0.5** | **10ëª…** | **70%** | **65%** | âœ… **Phase 1 ì¶”ì²œ** |
| 0.6 | 5ëª… | 85% | 50% | âš ï¸ ë„ˆë¬´ ë³´ìˆ˜ì  |
| 0.7 | 2ëª… | 95% | 30% | âŒ ë°ì´í„° ë¶€ì¡± |

**Phase 1 ê¶Œì¥ Threshold: 0.5 (50%)**

**ê·¼ê±°:**
1. **Precision 70%**: ì‚¬ìš©ìê°€ "ìœ ì‚¬í•˜ë‹¤"ê³  ë™ì˜í•˜ëŠ” ë¹„ìœ¨
2. **ìœ ì‚¬ í›„ë³´ì 10ëª…**: í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ íŒ¨í„´ ì¶”ì¶œ ê°€ëŠ¥ (ìµœì†Œ 3ëª… í•„ìš”)
3. **Recall 65%**: ì‹¤ì œ ìœ ì‚¬ í›„ë³´ìì˜ 65% í¬ì°© (Phase 2ì—ì„œ MLë¡œ ê°œì„ )

**ë™ì  Threshold ì¡°ì • (Phase 2):**
```python
def adaptive_threshold(candidate_pool_size: int) -> float:
    """
    í›„ë³´ì í’€ í¬ê¸°ì— ë”°ë¼ threshold ë™ì  ì¡°ì •
    """
    if candidate_pool_size < 100:
        return 0.4  # ë°ì´í„° ì ìœ¼ë©´ threshold ë‚®ì¶¤
    elif candidate_pool_size < 1000:
        return 0.5
    else:
        return 0.6  # ë°ì´í„° ë§ìœ¼ë©´ threshold ë†’ì„
```

---

### 3.3 Nëª…ì˜ ìœ ì‚¬ í›„ë³´ì íƒìƒ‰ ì„±ëŠ¥

**ë¬¸ì œ: í›„ë³´ì Aì— ëŒ€í•´ ìœ ì‚¬ë„ 0.5 ì´ìƒì¸ í›„ë³´ì ì°¾ê¸°**

#### **Naive Approach: ì „ìˆ˜ ë¹„êµ**

```python
def find_similar_candidates_naive(candidate_a_id: str, threshold: float) -> list:
    """
    ëª¨ë“  í›„ë³´ìì™€ ë¹„êµ (Brute Force)
    """
    similar_candidates = []
    candidate_a = get_candidate(candidate_a_id)

    # ëª¨ë“  ë‹¤ë¥¸ í›„ë³´ì ìˆœíšŒ
    for candidate_b in get_all_candidates():  # O(N)
        if candidate_b.id == candidate_a_id:
            continue

        similarity = weighted_jaccard_similarity(candidate_a, candidate_b)  # O(K) K=ìŠ¤í‚¬ ìˆ˜

        if similarity >= threshold:
            similar_candidates.append({
                'candidate_id': candidate_b.id,
                'similarity': similarity
            })

    return sorted(similar_candidates, key=lambda x: x['similarity'], reverse=True)
```

**Big O ë³µì¡ë„:**
- **Time Complexity**: O(N Ã— K)
  - N = ì „ì²´ í›„ë³´ì ìˆ˜
  - K = í‰ê·  ìŠ¤í‚¬ ìˆ˜
- **Space Complexity**: O(N)

**ì„±ëŠ¥ ì˜ˆì¸¡:**

| í›„ë³´ì ìˆ˜ (N) | í‰ê·  ìŠ¤í‚¬ (K) | ê³„ì‚° íšŸìˆ˜ | ì˜ˆìƒ ì‹œê°„ (Python) |
|--------------|--------------|----------|-------------------|
| 100 | 10 | 1,000 | 0.1ì´ˆ |
| 1,000 | 10 | 10,000 | 1ì´ˆ |
| 10,000 | 10 | 100,000 | 10ì´ˆ |
| 100,000 | 10 | 1,000,000 | **100ì´ˆ** âŒ |

**ê²°ë¡ : 10,000ëª… ì´ìƒì—ì„œëŠ” Naive Approach ë¶ˆê°€ëŠ¥**

---

#### **ìµœì í™” 1: Inverted Index (Skill-Based Lookup)**

**ì•„ì´ë””ì–´: "Python ìŠ¤í‚¬ì„ ê°€ì§„ í›„ë³´ì" ëª©ë¡ì„ ë¯¸ë¦¬ êµ¬ì¶•**

```python
# ì‚¬ì „ êµ¬ì¶• (Batch Job)
skill_to_candidates = {
    'skill_python': ['cand_1', 'cand_5', 'cand_12', ...],  # 1,000ëª…
    'skill_django': ['cand_1', 'cand_3', ...],  # 500ëª…
    ...
}

def find_similar_candidates_optimized(candidate_a_id: str, threshold: float) -> list:
    """
    Inverted Indexë¥¼ í™œìš©í•œ ë¹ ë¥¸ ê²€ìƒ‰
    """
    candidate_a = get_candidate(candidate_a_id)
    candidate_a_skills = set(candidate_a.skills.keys())

    # Step 1: í›„ë³´ì Aì˜ ìŠ¤í‚¬ ì¤‘ í•˜ë‚˜ë¼ë„ ê°€ì§„ í›„ë³´ì ì°¾ê¸° (Union)
    potential_candidates = set()
    for skill_id in candidate_a_skills:
        potential_candidates.update(skill_to_candidates.get(skill_id, []))

    # Step 2: Potential candidatesë§Œ ìœ ì‚¬ë„ ê³„ì‚° (O(M Ã— K), M << N)
    similar_candidates = []
    for candidate_b_id in potential_candidates:
        if candidate_b_id == candidate_a_id:
            continue

        candidate_b = get_candidate(candidate_b_id)
        similarity = weighted_jaccard_similarity(candidate_a, candidate_b)

        if similarity >= threshold:
            similar_candidates.append({
                'candidate_id': candidate_b_id,
                'similarity': similarity
            })

    return sorted(similar_candidates, key=lambda x: x['similarity'], reverse=True)
```

**Big O ë³µì¡ë„:**
- **Time Complexity**: O(S Ã— C + M Ã— K)
  - S = í›„ë³´ì Aì˜ ìŠ¤í‚¬ ìˆ˜ (ë³´í†µ 5-15ê°œ)
  - C = ìŠ¤í‚¬ë‹¹ í‰ê·  í›„ë³´ì ìˆ˜ (1,000ëª… ì¤‘ 100ëª… = 10%)
  - M = Potential candidates ìˆ˜ (ë³´í†µ Nì˜ 20-30%)
  - K = í‰ê·  ìŠ¤í‚¬ ìˆ˜
- **Space Complexity**: O(N Ã— K) (Inverted Index)

**ì„±ëŠ¥ ì˜ˆì¸¡:**

| í›„ë³´ì ìˆ˜ (N) | Potential (M) | ê³„ì‚° íšŸìˆ˜ | ì˜ˆìƒ ì‹œê°„ (Python) | ê°œì„ ìœ¨ |
|--------------|--------------|----------|-------------------|--------|
| 1,000 | 200 | 2,000 | 0.2ì´ˆ | **5ë°°** |
| 10,000 | 2,000 | 20,000 | 2ì´ˆ | **5ë°°** |
| 100,000 | 20,000 | 200,000 | 20ì´ˆ | **5ë°°** |

**ê²°ë¡ : 100,000ëª…ê¹Œì§€ ì‹¤ìš©ì **

---

#### **ìµœì í™” 2: Pre-Computed Similarity Matrix (Phase 2)**

**ì•„ì´ë””ì–´: ëª¨ë“  í›„ë³´ì ìŒì˜ ìœ ì‚¬ë„ë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•˜ì—¬ ì €ì¥**

```python
# Batch Job (ì•¼ê°„ ì‹¤í–‰)
similarity_matrix = {}  # {(cand_a, cand_b): similarity_score}

for i, candidate_a in enumerate(all_candidates):
    for candidate_b in all_candidates[i+1:]:  # ì¤‘ë³µ ê³„ì‚° ë°©ì§€
        similarity = weighted_jaccard_similarity(candidate_a, candidate_b)

        if similarity >= 0.3:  # ë‚®ì€ thresholdë¡œ ë¯¸ë¦¬ ê³„ì‚°
            similarity_matrix[(candidate_a.id, candidate_b.id)] = similarity
            similarity_matrix[(candidate_b.id, candidate_a.id)] = similarity  # ëŒ€ì¹­

# ì‹¤ì‹œê°„ ì¡°íšŒ (O(1))
def find_similar_candidates_precomputed(candidate_a_id: str, threshold: float) -> list:
    """
    ì‚¬ì „ ê³„ì‚°ëœ similarity matrix ì¡°íšŒ
    """
    similar_candidates = [
        {'candidate_id': cand_b_id, 'similarity': similarity}
        for (cand_a, cand_b_id), similarity in similarity_matrix.items()
        if cand_a == candidate_a_id and similarity >= threshold
    ]

    return sorted(similar_candidates, key=lambda x: x['similarity'], reverse=True)
```

**Trade-offs:**
- **ì¥ì **: ì‹¤ì‹œê°„ ì¡°íšŒ O(1) (ì¦‰ì‹œ ì‘ë‹µ)
- **ë‹¨ì **:
  - ì €ì¥ ê³µê°„: O(N^2) (100,000ëª… Ã— 100,000ëª… = 10B entries âŒ)
  - ê°±ì‹  ë¹„ìš©: ìƒˆ í›„ë³´ì ì¶”ê°€ ì‹œ Në²ˆ ê³„ì‚° í•„ìš”

**ì‹¤ìš©ì  ë³€í˜•: Sparse Matrix (ìœ ì‚¬ë„ â‰¥ 0.3ë§Œ ì €ì¥)**

| í›„ë³´ì ìˆ˜ (N) | ì „ì²´ ìŒ (N^2) | Sparse (5% ì €ì¥) | ì €ì¥ ê³µê°„ |
|--------------|--------------|-----------------|----------|
| 1,000 | 1M | 50K | 1MB |
| 10,000 | 100M | 5M | 100MB |
| 100,000 | 10B | 500M | **10GB** âš ï¸ |

**ê²°ë¡ : 10,000ëª…ê¹Œì§€ ì‹¤ìš©ì , ê·¸ ì´ìƒì€ Inverted Index ë°©ì‹ ì„ í˜¸**

---

### 3.4 ì¸ë±ì‹± ì „ëµ

#### **PostgreSQL ì¸ë±ì‹±**

```sql
-- 1. candidate_skills í…Œì´ë¸” ì¸ë±ìŠ¤
CREATE INDEX idx_candidate_skills_skill_id ON candidate_skills(skill_id);
CREATE INDEX idx_candidate_skills_candidate_id ON candidate_skills(candidate_id);

-- 2. ë³µí•© ì¸ë±ìŠ¤ (skill_id + proficiency_level)
CREATE INDEX idx_candidate_skills_composite
ON candidate_skills(skill_id, proficiency_level);

-- 3. GIN ì¸ë±ìŠ¤ (JSONB ìŠ¤í‚¬ ë°ì´í„°)
CREATE INDEX idx_candidate_skills_gin ON candidates USING GIN (skills);

-- 4. ìœ ì‚¬ë„ ê³„ì‚° ìµœì í™”: ARRAY íƒ€ì… í™œìš©
ALTER TABLE candidates ADD COLUMN skill_array TEXT[];
CREATE INDEX idx_candidate_skill_array ON candidates USING GIN (skill_array);
```

**ì¿¼ë¦¬ ì˜ˆì‹œ (GIN ì¸ë±ìŠ¤ í™œìš©):**
```sql
-- í›„ë³´ì Aì™€ ê³µí†µ ìŠ¤í‚¬ì´ ìˆëŠ” í›„ë³´ì ì°¾ê¸°
SELECT c2.id, c2.skill_array
FROM candidates c1
CROSS JOIN candidates c2
WHERE c1.id = 'cand_A'
  AND c1.skill_array && c2.skill_array  -- Array overlap operator (GIN ì¸ë±ìŠ¤ ì‚¬ìš©)
  AND c2.id != c1.id;
```

---

#### **Neo4j ì¸ë±ì‹±**

```cypher
// 1. Candidate ID ì¸ë±ìŠ¤
CREATE INDEX candidate_id_index FOR (c:Candidate) ON (c.id);

// 2. Skill ID ì¸ë±ìŠ¤
CREATE INDEX skill_id_index FOR (s:Skill) ON (s.id);

// 3. Composite ì¸ë±ìŠ¤ (Relationship Property)
CREATE INDEX has_skill_proficiency_index
FOR ()-[r:HAS_SKILL]-() ON (r.proficiency_level);

// 4. Full-text ì¸ë±ìŠ¤ (Skill Name)
CREATE FULLTEXT INDEX skill_name_fulltext FOR (s:Skill) ON EACH [s.canonical_name, s.synonyms];
```

**ì¿¼ë¦¬ ìµœì í™” (EXPLAIN ë¶„ì„):**
```cypher
// Before: Full scan
MATCH (a:Candidate {id: 'cand_A'})-[:HAS_SKILL]->(skill:Skill)
MATCH (similar:Candidate)-[:HAS_SKILL]->(skill)
RETURN similar;

// After: Index lookup
MATCH (a:Candidate)
WHERE a.id = 'cand_A'  // Index lookup
WITH a
MATCH (a)-[:HAS_SKILL]->(skill:Skill)
WITH a, COLLECT(skill) AS a_skills
MATCH (similar:Candidate)-[:HAS_SKILL]->(skill:Skill)
WHERE similar <> a AND skill IN a_skills  // Index-backed filter
RETURN similar;
```

---

## 4. ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ë° ì´ˆê¸° êµ¬ì¶•

### 4.1 Cold Start ì „ëµ

**ë¬¸ì œ: Skill ë°ì´í„°ê°€ ì „í˜€ ì—†ì„ ë•Œ ì–´ë–»ê²Œ ì‹œì‘í•˜ëŠ”ê°€?**

#### **ìµœì†Œ ë°ì´í„° ì„ê³„ê°’ (Minimum Viable Dataset)**

**Use Case 4ê°€ ì‘ë™í•˜ë ¤ë©´:**
1. **í›„ë³´ì ìˆ˜**: ìµœì†Œ 100ëª… (ìœ ì‚¬ë„ ê³„ì‚° ì˜ë¯¸ ìˆìœ¼ë ¤ë©´)
2. **ìŠ¤í‚¬ ì¢…ë¥˜**: ìµœì†Œ 5ê°œ ì¹´í…Œê³ ë¦¬ Ã— 3ê°œ ìŠ¤í‚¬ = 15ê°œ
3. **ìŠ¤í‚¬ ì»¤ë²„ë¦¬ì§€**: í›„ë³´ìë‹¹ í‰ê·  5-10ê°œ ìŠ¤í‚¬
4. **ê³¼ê±° ì´ë ¥**: ìµœì†Œ 50ê°œ ì§€ì› ê±´ (íƒˆë½ íŒ¨í„´ ë¶„ì„ ê°€ëŠ¥)

**ê³„ì‚°:**
```
ìµœì†Œ ë°ì´í„° = 100 candidates Ã— 7 skills/candidate Ã— 0.5 applications/candidate Ã— 3 stage_transitions/application
           = 100 Ã— 7 Ã— 0.5 Ã— 3
           = 1,050 data points
```

**í˜„ì‹¤ì  ëª©í‘œ (MVP):**
- **500ëª… í›„ë³´ì**
- **30ê°œ ìŠ¤í‚¬** (Backend, Frontend, Data Science ì£¼ìš” ìŠ¤í‚¬)
- **í‰ê·  8ê°œ ìŠ¤í‚¬/í›„ë³´ì**
- **200ê°œ ì§€ì› ì´ë ¥** (ìµœê·¼ 6ê°œì›”)

---

### 4.2 ê¸°ì¡´ ë°ì´í„°ì—ì„œ Skill ì¼ê´„ ì¶”ì¶œ

#### **Scenario 1: Resume PDF/Textê°€ ìˆëŠ” ê²½ìš°**

**Batch Processing Pipeline:**

```python
# Step 1: Resume Text Extraction
def extract_resume_text(resume_pdf: bytes) -> str:
    """
    PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (PyPDF2 ë˜ëŠ” OCR)
    """
    # ... PDF parsing logic
    return resume_text

# Step 2: LLM Skill Extraction (Batch)
def batch_extract_skills(resume_texts: list) -> list:
    """
    100ê°œì”© ë°°ì¹˜ ì²˜ë¦¬ (API ë¹„ìš© ì ˆê°)
    """
    batch_size = 100
    all_results = []

    for i in range(0, len(resume_texts), batch_size):
        batch = resume_texts[i:i+batch_size]

        # LLM API í˜¸ì¶œ (ì˜ˆ: OpenAI Batch API)
        prompt = f"""
        ë‹¤ìŒ {len(batch)}ê°œ ì´ë ¥ì„œì—ì„œ ìŠ¤í‚¬ì„ ì¶”ì¶œí•˜ì„¸ìš”.

        ì´ë ¥ì„œ ëª©ë¡:
        {json.dumps(batch, ensure_ascii=False)}

        ì¶œë ¥ í˜•ì‹:
        [
          {{"resume_id": 1, "skills": [...]}},
          {{"resume_id": 2, "skills": [...]}}
        ]
        """

        response = llm_api.complete(prompt, max_tokens=4096)
        all_results.extend(response)

    return all_results

# Step 3: Skill Normalization + DB ì €ì¥
def create_skill_links(candidate_id: str, extracted_skills: list):
    """
    ì¶”ì¶œëœ ìŠ¤í‚¬ì„ Skill Objectì™€ Linkë¡œ ë³€í™˜
    """
    for skill_data in extracted_skills:
        canonical_skill = normalize_skill(skill_data['canonical_skill'])

        if not canonical_skill:
            log_warning(f"Skill not recognized: {skill_data['raw_skill']}")
            continue

        # HAS_SKILL Link ìƒì„±
        create_link(
            from_id=candidate_id,
            to_id=canonical_skill.id,
            link_type='HAS_SKILL',
            properties={
                'proficiency_level': skill_data['proficiency_level'],
                'years_of_experience': skill_data['years_of_experience'],
                'verified': False,
                'source': 'resume',
                'extraction_confidence': skill_data['confidence']
            }
        )
```

**ì˜ˆìƒ ë¹„ìš© (OpenAI GPT-4):**
- ì´ë ¥ì„œ 500ê°œ
- í‰ê·  í† í°: 1,000 tokens/resume (input) + 200 tokens/resume (output)
- ì´ í† í°: 500 Ã— 1,200 = 600,000 tokens
- ë¹„ìš©: 600K tokens Ã— $0.03/1K tokens (GPT-4 Turbo) = **$18**

---

#### **Scenario 2: Resumeê°€ ì—†ê³  Job Applicationë§Œ ìˆëŠ” ê²½ìš°**

**ì—­ì¶”ë¡  ì „ëµ:**

```python
def infer_skills_from_job_posting(candidate_id: str, job_posting_id: str):
    """
    ì§€ì›í•œ Job Postingì˜ Required Skillsë¡œë¶€í„° ì¶”ë¡ 
    """
    job_posting = get_job_posting(job_posting_id)
    required_skills = job_posting.required_skills  # [Skill IDs]

    for skill_id in required_skills:
        # ê°€ì •: ì§€ì›í•œ ê³µê³ ì˜ ìŠ¤í‚¬ì€ í›„ë³´ìë„ ë³´ìœ 
        create_link(
            from_id=candidate_id,
            to_id=skill_id,
            link_type='HAS_SKILL',
            properties={
                'proficiency_level': 'intermediate',  # Default
                'verified': False,
                'source': 'inferred_from_job_posting',
                'confidence': 0.5  # ë‚®ì€ ì‹ ë¢°ë„
            }
        )
```

**ìœ„í—˜:**
- False Positive ë†’ìŒ (ì§€ì›í–ˆë‹¤ê³  ìŠ¤í‚¬ì´ ìˆëŠ” ê±´ ì•„ë‹˜)
- Confidence score ëª…ì‹œ í•„ìˆ˜ (0.5 ì´í•˜)

---

#### **Scenario 3: Manual Input (ìµœí›„ ìˆ˜ë‹¨)**

**UI ì œê³µ:**
```
í›„ë³´ì í”„ë¡œí•„ í˜ì´ì§€:

[ + ìŠ¤í‚¬ ì¶”ê°€ ]

ìŠ¤í‚¬ ì…ë ¥: [Python         â–¼]  ìë™ì™„ì„±
ìˆ™ë ¨ë„:     [Advanced       â–¼]  ë“œë¡­ë‹¤ìš´
ê²½ë ¥ ë…„ìˆ˜:   [5              ]  ìˆ«ì ì…ë ¥

[ì €ì¥]
```

**ë°ì´í„° í’ˆì§ˆ:**
- Verified: True (ì‚¬ëŒì´ ì…ë ¥)
- Source: "manual_input"
- Confidence: 1.0

---

### 4.3 ë°ì´í„° í’ˆì§ˆ ê²€ì¦ í”„ë¡œì„¸ìŠ¤

#### **Validation Rules**

```python
def validate_skill_data_quality():
    """
    ë°°ì¹˜ ì‘ì—…ìœ¼ë¡œ ë°ì´í„° í’ˆì§ˆ ì ê²€
    """
    issues = []

    # Rule 1: í›„ë³´ìë‹¹ ìµœì†Œ ìŠ¤í‚¬ ìˆ˜
    candidates_without_skills = query("""
        SELECT candidate_id
        FROM candidates c
        LEFT JOIN candidate_skills cs ON c.id = cs.candidate_id
        GROUP BY c.id
        HAVING COUNT(cs.skill_id) < 3
    """)

    if len(candidates_without_skills) > 100:
        issues.append(f"âš ï¸ {len(candidates_without_skills)}ëª…ì´ ìŠ¤í‚¬ 3ê°œ ë¯¸ë§Œ")

    # Rule 2: Skill Objectê°€ ì‹¤ì œ ì‚¬ìš©ë˜ëŠ”ê°€?
    unused_skills = query("""
        SELECT s.id, s.canonical_name
        FROM skills s
        LEFT JOIN candidate_skills cs ON s.id = cs.skill_id
        WHERE cs.skill_id IS NULL
    """)

    if unused_skills:
        issues.append(f"âš ï¸ {len(unused_skills)}ê°œ ìŠ¤í‚¬ì´ ë¯¸ì‚¬ìš© (ì‚­ì œ ê³ ë ¤)")

    # Rule 3: Confidence < 0.7ì¸ ìŠ¤í‚¬ ë¹„ìœ¨
    low_confidence_ratio = query("""
        SELECT
            COUNT(CASE WHEN extraction_confidence < 0.7 THEN 1 END)::FLOAT / COUNT(*) AS ratio
        FROM candidate_skills
    """)[0]['ratio']

    if low_confidence_ratio > 0.3:
        issues.append(f"âš ï¸ ì €ì‹ ë¢°ë„ ìŠ¤í‚¬ì´ {low_confidence_ratio*100:.1f}% (ëª©í‘œ: 30% ì´í•˜)")

    # Rule 4: ë™ì˜ì–´ ì •ê·œí™” ì‹¤íŒ¨ ê±´ìˆ˜
    non_canonical_skills = query("""
        SELECT raw_skill, COUNT(*) AS cnt
        FROM candidate_skills
        WHERE canonical_skill IS NULL
        GROUP BY raw_skill
        ORDER BY cnt DESC
        LIMIT 10
    """)

    if non_canonical_skills:
        issues.append(f"âš ï¸ ì •ê·œí™” ì‹¤íŒ¨ ìŠ¤í‚¬ Top 10: {non_canonical_skills}")

    return issues
```

**ì£¼ê°„ ë¦¬í¬íŠ¸ ì˜ˆì‹œ:**
```
=== Skill Data Quality Report (2026-01-07) ===

ì´ í›„ë³´ì: 1,234ëª…
ì´ ìŠ¤í‚¬: 45ê°œ
ì´ HAS_SKILL Links: 8,765ê°œ
í‰ê·  ìŠ¤í‚¬/í›„ë³´ì: 7.1ê°œ

âœ… í†µê³¼:
- í›„ë³´ìë‹¹ í‰ê·  ìŠ¤í‚¬ ìˆ˜: 7.1ê°œ (ëª©í‘œ: 5-10ê°œ)
- Confidence â‰¥ 0.7 ë¹„ìœ¨: 78% (ëª©í‘œ: 70% ì´ìƒ)

âš ï¸ ê°œì„  í•„ìš”:
- 152ëª…ì˜ í›„ë³´ìê°€ ìŠ¤í‚¬ 3ê°œ ë¯¸ë§Œ â†’ ìˆ˜ë™ ì…ë ¥ ê¶Œì¥
- "NumPy" ìŠ¤í‚¬ì´ 25íšŒ ì¶”ì¶œë˜ì—ˆìœ¼ë‚˜ Skill DBì— ì—†ìŒ â†’ ì¶”ê°€ í•„ìš”
- "python3" â†’ "Python" ì •ê·œí™” ì‹¤íŒ¨ 12ê±´ â†’ Synonym map ì—…ë°ì´íŠ¸

ğŸ”´ ê¸´ê¸‰:
- ì—†ìŒ

ë‹¤ìŒ ì•¡ì…˜:
1. "NumPy" Skill Object ìƒì„± (owner: Terry)
2. Synonym mapì— "python3" ì¶”ê°€ (owner: Dev Team)
3. 152ëª… í›„ë³´ì ì¤‘ ìµœê·¼ ì§€ì›ì 50ëª…ì—ê²Œ ìŠ¤í‚¬ ì…ë ¥ ìš”ì²­ ì´ë©”ì¼ ë°œì†¡ (owner: Recruiter)
```

---

## 5. ì˜¨í†¨ë¡œì§€ vs ì¼ë°˜ DB ë¹„êµ ì¦ëª…

### 5.1 MVP ì„±ê³µ ê¸°ì¤€ ì¬ê²€ì¦

**í˜„ì¬ ëª©í‘œ (ontology-pm-strategy.md):**

> **ì˜¨í†¨ë¡œì§€ vs ì¼ë°˜ DB ë¹„êµ ì¦ëª…**
> - ë³µì¡í•œ ê´€ê³„ ì¿¼ë¦¬ (3-hop ì´ìƒ): ì¼ë°˜ DB ëŒ€ë¹„ **2ë°° ì´ìƒ ë¹ ë¦„**
> - ìœ ì‚¬ë„ ê³„ì‚° ì •í™•ë„: ì‚¬ìš©ì ê²€ì¦ **70% ì´ìƒ**
> - ë§¥ë½ ê¸°ë°˜ ë¶„ì„: ì¼ë°˜ SQLë¡œëŠ” êµ¬í˜„ **ë¶ˆê°€ëŠ¥** ì¦ëª…

#### **5.1.1 ì„±ëŠ¥ ë¹„êµ ("2ë°° ë¹ ë¦„" ê²€ì¦)**

**ë²¤ì¹˜ë§ˆí¬ ì‹œë‚˜ë¦¬ì˜¤:**

**Scenario A: ìœ ì‚¬ í›„ë³´ì 3ëª… ì°¾ê¸°**
- í›„ë³´ì 1,000ëª…
- í‰ê·  ìŠ¤í‚¬ 10ê°œ
- ìœ ì‚¬ë„ threshold 0.5
- ìµœê·¼ 12ê°œì›” ì§€ì› ì´ë ¥

**PostgreSQL êµ¬í˜„:**
```sql
-- ì•ì„œ ì‘ì„±í•œ 60ì¤„ SQL ì¿¼ë¦¬
-- ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„: 3ì´ˆ (ì¸ë±ìŠ¤ ìµœì í™” í›„)
```

**Neo4j êµ¬í˜„:**
```cypher
// ì•ì„œ ì‘ì„±í•œ 30ì¤„ Cypher ì¿¼ë¦¬
// ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„: 0.5ì´ˆ
```

**ì˜ˆìƒ ì„±ëŠ¥ ë¹„ìœ¨: 6ë°°**

**ì‹¤ì œ ì¸¡ì • í•„ìš” (Action Item):**
```python
# Benchmark script
import time

# PostgreSQL
start = time.time()
pg_result = execute_sql(postgresql_query)
pg_time = time.time() - start

# Neo4j
start = time.time()
neo4j_result = execute_cypher(neo4j_query)
neo4j_time = time.time() - start

speedup = pg_time / neo4j_time
print(f"Performance: Neo4j is {speedup:.1f}x faster")
```

**ëª©í‘œ: ì‹¤ì œ ë°ì´í„°ë¡œ 5ë°° ì´ìƒ ì¦ëª…**

---

#### **5.1.2 ì •í™•ë„ ë¹„êµ ("70% ì´ìƒ" ê²€ì¦)**

**User Validation Study:**

```
í”„ë¡œí† ì½œ:
1. 50ëª…ì˜ í›„ë³´ì ìƒ˜í”Œ ì„ ì •
2. ê° í›„ë³´ìì— ëŒ€í•´ SIMILAR_TO ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ Top 5 ìœ ì‚¬ í›„ë³´ì ì¶”ì¶œ
3. ì‚¬ëŒ (ì±„ìš© ë‹´ë‹¹ì 3ëª…)ì´ ë…ë¦½ì ìœ¼ë¡œ í‰ê°€:
   - "ì‹¤ì œë¡œ ìœ ì‚¬í•œê°€?" (Yes/No)
   - "ìœ ì‚¬ë„ ì ìˆ˜ê°€ ì ì ˆí•œê°€?" (1-5 scale)
4. Inter-rater agreement ì¸¡ì • (Fleiss' Kappa)

ê²°ê³¼ ì˜ˆì‹œ:
- 50 candidates Ã— 5 similar candidates = 250 pairs
- Human label: 175 pairs "Yes" (70%)
- Algorithm label (threshold 0.5): 180 pairs
- True Positive: 165
- Precision: 165 / 180 = 91.7% âœ…
- Recall: 165 / 175 = 94.3% âœ…
```

**ëª©í‘œ: Precision 70% ì´ìƒ (ì‹¤ì œë¡œëŠ” 90%+ ì˜ˆìƒ)**

---

#### **5.1.3 "ì¼ë°˜ SQL ë¶ˆê°€ëŠ¥" ì¦ëª…**

**Claim: ë§¥ë½ ê¸°ë°˜ ë¶„ì„ì€ ì¼ë°˜ SQLë¡œëŠ” êµ¬í˜„ ë¶ˆê°€ëŠ¥**

**ë°˜ì¦: ì‹¤ì œë¡œëŠ” ê°€ëŠ¥í•˜ë‹¤ (í•˜ì§€ë§Œ ë¹„ì‹¤ìš©ì )**

**ì •í™•í•œ ì£¼ì¥:**
âœ… "ì¼ë°˜ SQLë¡œëŠ” **ì‹¤ìš©ì ì´ì§€ ì•ŠìŒ**"
- ì¿¼ë¦¬ ë³µì¡ë„: 60+ ì¤„ (ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€)
- ì„±ëŠ¥: 3ì´ˆ vs 0.5ì´ˆ (6ë°° ì°¨ì´)
- í™•ì¥ì„±: Nì´ ì»¤ì§ˆìˆ˜ë¡ JOIN í­ë°œ

**ì¦ëª… ë°©ë²•:**

```
ë¹„êµ í…Œì´ë¸”:

| ì¸¡ë©´ | PostgreSQL | Neo4j | íŒì • |
|------|------------|-------|------|
| **ì¿¼ë¦¬ ê°€ë…ì„±** | 60ì¤„, ë³µì¡í•œ Subquery | 30ì¤„, ì„ ì–¸ì  | Neo4j ìŠ¹ |
| **ì„±ëŠ¥ (1K)** | 3ì´ˆ | 0.5ì´ˆ | Neo4j ìŠ¹ |
| **ì„±ëŠ¥ (10K)** | 25ì´ˆ | 2ì´ˆ | Neo4j ìŠ¹ |
| **ìœ ì§€ë³´ìˆ˜ì„±** | SQL ì „ë¬¸ê°€ í•„ìš” | PMë„ ì´í•´ ê°€ëŠ¥ | Neo4j ìŠ¹ |
| **í™•ì¥ì„±** | O(NÃ—MÃ—K) | O(dÃ—b) | Neo4j ìŠ¹ |
```

**ê²°ë¡ : "ê¸°ìˆ ì ìœ¼ë¡œ ê°€ëŠ¥í•˜ì§€ë§Œ ë¹„ì¦ˆë‹ˆìŠ¤ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥"**

---

### 5.2 PostgreSQL + pg_trgm ë¹„êµ

**ì§ˆë¬¸: PostgreSQLì˜ pg_trgm (Trigram) í™•ì¥ìœ¼ë¡œ ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥í•œë° ì°¨ì´ëŠ”?**

#### **pg_trgm ì†Œê°œ**

```sql
-- pg_trgm í™•ì¥ í™œì„±í™”
CREATE EXTENSION pg_trgm;

-- í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°
SELECT similarity('Python Developer', 'Python Engineer');
-- ê²°ê³¼: 0.615 (61.5% ìœ ì‚¬)

-- ìœ ì‚¬í•œ ìŠ¤í‚¬ ê²€ìƒ‰
SELECT skill_name, similarity(skill_name, 'Python') AS sim
FROM skills
WHERE skill_name % 'Python'  -- % operator: similarity threshold
ORDER BY sim DESC
LIMIT 5;
```

**pg_trgmì˜ ì¥ì :**
1. PostgreSQL ë„¤ì´í‹°ë¸Œ ì§€ì› (ë³„ë„ DB ë¶ˆí•„ìš”)
2. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° ë¹ ë¦„ (GIN/GiST ì¸ë±ìŠ¤)
3. Fuzzy matching ê°€ëŠ¥ ("Python" â‰ˆ "python" â‰ˆ "Pyhton")

---

#### **pg_trgm vs Graph DB ë¹„êµ**

**Use Case 4ì— ì ìš© ì‹œ:**

**PostgreSQL + pg_trgm:**
```sql
-- Step 1: í›„ë³´ì Aì˜ ìŠ¤í‚¬ í…ìŠ¤íŠ¸ë¡œ ìœ ì‚¬ í›„ë³´ì ì°¾ê¸°
WITH candidate_a_skills_text AS (
  SELECT STRING_AGG(s.canonical_name, ' ') AS skill_text
  FROM candidates c
  JOIN candidate_skills cs ON c.id = cs.candidate_id
  JOIN skills s ON cs.skill_id = s.id
  WHERE c.id = 'cand_A'
)

SELECT
  c2.id,
  similarity(
    (SELECT skill_text FROM candidate_a_skills_text),
    STRING_AGG(s2.canonical_name, ' ')
  ) AS text_similarity
FROM candidates c2
JOIN candidate_skills cs2 ON c2.id = cs2.candidate_id
JOIN skills s2 ON cs2.skill_id = s2.id
WHERE c2.id != 'cand_A'
GROUP BY c2.id
HAVING similarity(...) > 0.5;
```

**ë¬¸ì œì :**

1. **ìˆ™ë ¨ë„(proficiency) ë¬´ì‹œ**
   - "Python beginner" vs "Python expert" â†’ ë˜‘ê°™ì´ ì·¨ê¸‰
   - pg_trgmì€ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ë§Œ ê³„ì‚° (ì˜ë¯¸ë¡ ì  ê°€ì¤‘ì¹˜ ì—†ìŒ)

2. **ê´€ê³„ ì¶”ë¡  ë¶ˆê°€**
   - "ìœ ì‚¬ í›„ë³´ì" â†’ "íƒˆë½ ì´ë ¥" â†’ "íƒˆë½ ì´ìœ "
   - ì—¬ì „íˆ 3ê°œ í…Œì´ë¸” JOIN í•„ìš” (pg_trgmì€ ìœ ì‚¬ë„ë§Œ í•´ê²°)

3. **ë™ì  ê³„ì‚° í•„ìš”**
   - `STRING_AGG()` ë§¤ë²ˆ ì‹¤í–‰ (ìºì‹± ë¶ˆê°€)
   - Candidate ìˆ˜ê°€ ë§ìœ¼ë©´ GROUP BY ë¹„ìš© ì¦ê°€

**Neo4jì˜ ìš°ìœ„:**
- Skillë³„ ê°€ì¤‘ì¹˜ ì ìš© ê°€ëŠ¥ (proficiency_level property)
- Graph Traversalë¡œ ê´€ê³„ ì¶”ë¡  í•œ ë²ˆì— í•´ê²°
- SIMILAR_TO Linkë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•˜ì—¬ ì €ì¥ (ìºì‹±)

---

#### **í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ (ì¶”ì²œ)**

**Phase 1 (MVP): PostgreSQL + Inverted Index**
- pg_trgmì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì˜¤ë²„í‚¬)
- Weighted Jaccard + Inverted Indexë¡œ ì¶©ë¶„
- ì´ìœ : 10,000ëª… ì´í•˜ì—ì„œëŠ” ì„±ëŠ¥ ë¬¸ì œ ì—†ìŒ

**Phase 2 (Scale-up): Neo4j ë„ì…**
- 10,000ëª… ì´ìƒ or ë³µì¡í•œ ê´€ê³„ ì¶”ë¡  í•„ìš” ì‹œ
- SIMILAR_TO Linkë¥¼ Graph DBì— ì €ì¥
- í•˜ì´ë¸Œë¦¬ë“œ: PostgreSQL (íŠ¸ëœì­ì…˜) + Neo4j (ë¶„ì„)

**Phase 3 (Advanced): Vector Embedding**
- ML ëª¨ë¸ë¡œ Skill Embedding (Word2Vec, BERT)
- "Python" â†” "Django" ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ìë™ í•™ìŠµ
- Vector DB (Pinecone, Weaviate) ì‚¬ìš©

---

### 5.3 Graph DB (Neo4j) ë„ì… ë¹„ìš© ëŒ€ë¹„ ì´ë“

#### **ë¹„ìš© ë¶„ì„**

**ë„ì… ë¹„ìš©:**

1. **ì¸í”„ë¼ ë¹„ìš©**
   - Neo4j Cloud (Aura): $65/month (Starter)
   - ë˜ëŠ” Self-Hosted: EC2 t3.medium ($30/month)

2. **ê°œë°œ ë¹„ìš©**
   - Neo4j í•™ìŠµ: 1-2ì£¼ (Cypher ì¿¼ë¦¬ ì–¸ì–´)
   - ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸: 1ì£¼
   - API í†µí•©: 1-2ì£¼
   - **ì´ ê°œë°œ ê³µìˆ˜: 4-5ì£¼**

3. **ìœ ì§€ë³´ìˆ˜ ë¹„ìš©**
   - DB ëª¨ë‹ˆí„°ë§ + ë°±ì—…: ì‹œê°„/ì£¼
   - ì¿¼ë¦¬ ìµœì í™”: í•„ìš” ì‹œ

**ì´ ë¹„ìš© (3ê°œì›” MVP):**
- ì¸í”„ë¼: $65 Ã— 3 = $195
- ê°œë°œ: 5ì£¼ Ã— $2,000/week (ê°œë°œì ì‹œê¸‰) = $10,000
- **ì´ $10,195**

---

**ì´ë“ ë¶„ì„:**

**ì •ëŸ‰ì  ì´ë“:**

1. **ì¿¼ë¦¬ ì„±ëŠ¥ ê°œì„ **
   - PostgreSQL: 3ì´ˆ â†’ Neo4j: 0.5ì´ˆ
   - ì‚¬ìš©ì ê²½í—˜: 6ë°° ê°œì„ 
   - ì±„ìš© ë‹´ë‹¹ì ì‹œê°„ ì ˆì•½: í•˜ë£¨ 30íšŒ ì¡°íšŒ Ã— 2.5ì´ˆ = 75ì´ˆ/ì¼ â†’ ì—°ê°„ **5ì‹œê°„ ì ˆì•½**

2. **ë³µì¡í•œ Use Case ê°€ëŠ¥**
   - Use Case 4 (ìœ„í—˜ ì‹œê·¸ë„): PostgreSQLë¡œëŠ” 30ì´ˆ+ â†’ ì‹¤ìš© ë¶ˆê°€
   - Neo4jë¡œë§Œ ê°€ëŠ¥ â†’ **ì‹ ê·œ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜**

3. **í™•ì¥ì„±**
   - PostgreSQL: 10,000ëª…ë¶€í„° ì„±ëŠ¥ ì €í•˜
   - Neo4j: 100,000ëª…ê¹Œì§€ ì„ í˜• í™•ì¥

**ì •ì„±ì  ì´ë“:**

1. **PM ììœ¨ì„±**
   - CypherëŠ” SQLë³´ë‹¤ ì§ê´€ì 
   - PMì´ ì§ì ‘ ì¿¼ë¦¬ ì‘ì„± ê°€ëŠ¥ â†’ ê°œë°œ ì˜ì¡´ë„ ê°ì†Œ

2. **ì˜¨í†¨ë¡œì§€ ì§„í™”**
   - ìƒˆ ê´€ê³„ ì¶”ê°€ ì‹œ ìŠ¤í‚¤ë§ˆ ë³€ê²½ ìµœì†Œí™”
   - "í›„ë³´ì ì¶”ì²œ" ê°™ì€ ê³ ê¸‰ Use Case ì‰½ê²Œ í™•ì¥

3. **ë§ˆì¼€íŒ… ê°€ì¹˜**
   - "AI-powered Graph Database" â†’ ê¸°ìˆ  ì°¨ë³„í™”
   - íˆ¬ìì/ê³ ê°ì—ê²Œ ì–´í•„

---

**ROI ê³„ì‚°:**

```
ë¹„ìš©: $10,195
ì´ë“:
- ì„±ëŠ¥ ê°œì„ : ì±„ìš© ë‹´ë‹¹ì ì‹œê°„ ì ˆì•½ (5ì‹œê°„/ë…„ Ã— $50/hour) = $250/ë…„
- ì‹ ê·œ ê¸°ëŠ¥: Use Case 4 ì œê³µ â†’ ê³ ê° ë§Œì¡±ë„ ì¦ê°€ â†’ Churn ê°ì†Œ (ì¶”ì • $5,000/ë…„)
- PM íš¨ìœ¨ì„±: ì¿¼ë¦¬ ì‘ì„± ì‹œê°„ 50% ê°ì†Œ â†’ ê°œë°œ ê³µìˆ˜ ì ˆê° (ì¶”ì • $3,000/ë…„)

ì—°ê°„ ì´ë“: $8,250
Payback Period: 10,195 / 8,250 = **1.2ë…„**
```

**ê²°ë¡ : ì´ë“ì´ ëª…í™•í•˜ë‹¤**

---

#### **ìœ„í—˜ ìš”ì†Œ**

1. **í•™ìŠµ ê³¡ì„ **
   - íŒ€ì´ Neo4j ë¯¸ê²½í—˜ ì‹œ ì´ˆê¸° ìƒì‚°ì„± ì €í•˜
   - Mitigation: 1ì£¼ ì§‘ì¤‘ êµìœ¡ + ì™¸ë¶€ ì»¨ì„¤í„´íŠ¸

2. **ìš´ì˜ ë³µì¡ë„**
   - PostgreSQL + Neo4j ë‘ ê°œ DB ê´€ë¦¬
   - Mitigation: í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ ëª…í™•íˆ ì •ì˜

3. **ë²¤ë” ë½ì¸**
   - Neo4j ì˜ì¡´ì„± ì¦ê°€
   - Mitigation: Cypherë¥¼ í‘œì¤€ Gremlinìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥ (í˜¸í™˜ì„±)

---

## 6. Phase 3ì—ì„œ MVPë¡œ ìŠ¹ê²© ì •ë‹¹ì„±

### 6.1 í˜„ì¬ ì œì•ˆ ë¶„ì„

**ontology-pm-strategy.mdì˜ MVP Objects (9ê°œ):**
1. Candidate
2. Job Posting
3. Application
4. Recruitment Stage
5. Stage Transition
6. Interview
7. Evaluation
8. AI_Recommendation
9. **Skill** â† Phase 3ì—ì„œ MVPë¡œ ìŠ¹ê²©

**ìŠ¹ê²© ê·¼ê±°:**
> "Use Case 4 (ìœ„í—˜ ì‹œê·¸ë„)ë¥¼ ìœ„í•´ Skill í•„ìˆ˜"

---

### 6.2 ë¬¸ì œì : MVP ê³¼ë¶€í•˜

#### **Skill Objectë¥¼ MVPì— í¬í•¨ ì‹œ ë¦¬ìŠ¤í¬:**

1. **ê°œë°œ ê¸°ê°„ ì¦ê°€**
   - Skill Taxonomy ì •ì˜: 2ì£¼
   - Normalization Pipeline êµ¬ì¶•: 3ì£¼
   - LLM í†µí•© + í…ŒìŠ¤íŠ¸: 2ì£¼
   - ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜: 2ì£¼
   - **ì´ 9ì£¼ ì¶”ê°€** (ê¸°ì¡´ 12ì£¼ â†’ **21ì£¼**)

2. **ë°ì´í„° í’ˆì§ˆ ë¦¬ìŠ¤í¬**
   - Skill ë°ì´í„° ìˆ˜ì§‘ í•„ìš” (í›„ë³´ì 500ëª… Ã— ì´ë ¥ì„œ ì¶”ì¶œ)
   - LLM ì •í™•ë„ ê²€ì¦ (ìµœì†Œ 100ê°œ ìƒ˜í”Œ)
   - Human-in-the-loop í”„ë¡œì„¸ìŠ¤ êµ¬ì¶•
   - **Cold Start ë¬¸ì œ í•´ê²° í•„ìˆ˜**

3. **MVP ë³µì¡ë„ ì¦ê°€**
   - 9ê°œ Objects â†’ ê´€ê³„ ë³µì¡ë„ O(N^2)
   - PMì´ ì´í•´í•˜ê¸° ì–´ë ¤ì›Œì§
   - ë°°í¬ ìœ„í—˜ë„ ì¦ê°€

---

### 6.3 ëŒ€ì•ˆ: ë‹¨ê³„ì  ì ‘ê·¼

#### **Option A: Use Case 1ë§Œ MVP (ì¶”ì²œ)**

**MVP Scope:**
- **Use Case 1**: ì§€ì›ì ë¦¬ë“œíƒ€ì„ ë¶„ì„ ë° ë³‘ëª© ì•Œë¦¼
- **Objects**: Candidate, Application, StageTransition, RecruitmentStage, AI_Recommendation (5ê°œ)
- **Links**: PROGRESSES_TO, RECOMMENDS_FOR (2ê°œ)

**ì¥ì :**
- ê°œë°œ ê¸°ê°„: **8ì£¼** (ë¹ ë¥¸ ì¶œì‹œ)
- Skill ì—†ì´ë„ ê°€ì¹˜ ì¦ëª… ê°€ëŠ¥
- ì˜¨í†¨ë¡œì§€ í•„ìš”ì„± ì…ì¦: 3-hop ì¡°ì¸ (Application â†’ StageTransition â†’ RecruitmentStage)

**ë‹¨ì :**
- Use Case 4ëŠ” Phase 2ë¡œ ì—°ê¸°

---

#### **Option B: Use Case 2ë„ í¬í•¨ (Skill ì—†ì´)**

**MVP Scope:**
- **Use Case 1**: ë¦¬ë“œíƒ€ì„ ë¶„ì„
- **Use Case 2**: ìœ ì‚¬ í›„ë³´ì ë¶„ì„ (ë‹¨, Skillì´ ì•„ë‹Œ Job Posting ê¸°ë°˜)
- **Objects**: ìœ„ 5ê°œ + JobPosting, Interview, Evaluation (8ê°œ)
- **Links**: APPLIES_TO, SCHEDULES, EVALUATES (ì¶”ê°€ 3ê°œ)

**ìœ ì‚¬ë„ ê³„ì‚° (Skill ì—†ì´):**
```cypher
// ê°™ì€ Job Postingì— ì§€ì›í•œ í›„ë³´ì = ìœ ì‚¬ í”„ë¡œí•„
MATCH (a:Candidate)-[:APPLIES_TO]->(job:JobPosting)<-[:APPLIES_TO]-(similar:Candidate)
WHERE a <> similar
WITH similar, COUNT(*) AS common_jobs
WHERE common_jobs >= 2  // ìµœì†Œ 2ê°œ ì´ìƒ ê³µí†µ ì§€ì›
RETURN similar, common_jobs
```

**ì¥ì :**
- Skill ë°ì´í„° ë¶ˆí•„ìš”
- Use Case 2 ê°€ì¹˜ ì œê³µ (ë©´ì ‘ê´€ ì§€ì›)
- ê°œë°œ ê¸°ê°„: **10ì£¼** (ìˆ˜ìš© ê°€ëŠ¥)

**ë‹¨ì :**
- ìœ ì‚¬ë„ ì •í™•ë„ ë‚®ìŒ (Job Posting ê¸°ë°˜ì€ ë„ˆë¬´ ê´‘ë²”ìœ„)

---

#### **Option C: Skillì„ MVPì— í¬í•¨ (í˜„ì¬ ì œì•ˆ)**

**ì¥ì :**
- Use Case 1, 2, 4 ëª¨ë‘ ì œê³µ
- ì˜¨í†¨ë¡œì§€ ê°€ì¹˜ ìµœëŒ€í™”

**ë‹¨ì :**
- ê°œë°œ ê¸°ê°„: **21ì£¼** (MVP ì‹¤íŒ¨ ìœ„í—˜)
- ë°ì´í„° í’ˆì§ˆ ë¦¬ìŠ¤í¬ ë†’ìŒ
- PM ê´€ë¦¬ ë³µì¡ë„ ì¦ê°€

---

### 6.4 ìµœì¢… ì¶”ì²œ

**âœ… Option A: Use Case 1ë§Œ MVP**

**ê·¼ê±°:**

1. **MVP ëª©í‘œ ì¬í™•ì¸:**
   > "ì˜¨í†¨ë¡œì§€ê°€ ì™œ í•„ìš”í•œì§€ ëª…í™•íˆ ì¦ëª…"

   - Use Case 1ë§Œìœ¼ë¡œë„ 3-hop ì¡°ì¸ ì¦ëª… ê°€ëŠ¥
   - ì„±ëŠ¥ ë¹„êµ (PostgreSQL vs Neo4j) ì¸¡ì • ê°€ëŠ¥
   - AI_Recommendation Objectë¡œ AI ì² í•™ êµ¬í˜„ ê°€ëŠ¥

2. **ë¹ ë¥¸ ì¶œì‹œ ìš°ì„ :**
   - 8ì£¼ vs 21ì£¼ â†’ **13ì£¼ ë‹¨ì¶•**
   - Time-to-Market ì¤‘ìš” (ê²½ìŸ ìš°ìœ„)

3. **ë°ì´í„° í’ˆì§ˆ í™•ë³´ ì‹œê°„:**
   - MVP ë°°í¬ í›„ 3ê°œì›”ê°„ Skill ë°ì´í„° ìˆ˜ì§‘
   - Phase 2ì—ì„œ ì¶©ë¶„í•œ ë°ì´í„°ë¡œ Use Case 4 ì¶œì‹œ

4. **í•™ìŠµ ê¸°íšŒ:**
   - MVPë¡œ ì˜¨í†¨ë¡œì§€ ìš´ì˜ ê²½í—˜ ì¶•ì 
   - PMì´ ì¿¼ë¦¬ ë¹Œë” ìµíˆê¸°
   - Phase 2 ì„¤ê³„ ì‹œ êµí›ˆ ë°˜ì˜

---

**Phase ê³„íš ì¬ì¡°ì •:**

```
Phase 1 (MVP, 8ì£¼):
  - Use Case 1: ë¦¬ë“œíƒ€ì„ ë¶„ì„
  - Objects: Candidate, Application, StageTransition, RecruitmentStage, AI_Recommendation
  - ì„±ê³µ ê¸°ì¤€: ë³‘ëª© ì•Œë¦¼ ì •í™•ë„ Â±3ì¼, AI ì œì•ˆ ìˆ˜ë½ë¥  60%+

Phase 2 (MVP + 4ê°œì›”):
  - Use Case 2: ìœ ì‚¬ í›„ë³´ì ë¶„ì„ (Skill ê¸°ë°˜)
  - Use Case 4: ìœ„í—˜ ì‹œê·¸ë„ ì¡°ê¸° ê°ì§€
  - Objects ì¶”ê°€: Skill, Interviewer, Evaluation
  - ë°ì´í„° êµ¬ì¶•: Skill Taxonomy + LLM ì¶”ì¶œ íŒŒì´í”„ë¼ì¸
  - ì„±ê³µ ê¸°ì¤€: ìœ ì‚¬ë„ ì •í™•ë„ 70%+, ìœ„í—˜ ì‹œê·¸ë„ ì •í™•ë„ 70%+

Phase 3 (MVP + 8ê°œì›”):
  - Use Case 3: ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ ë¶„ì„
  - Objects ì¶”ê°€: Communication, Recruiter, HiringManager
```

---

## 7. ìµœì¢… ì‚°ì¶œë¬¼

### 7.1 Use Case 4 ì¿¼ë¦¬ ì˜ˆì‹œ (Pseudo-code)

#### **Scenario: í›„ë³´ì Aì— ëŒ€í•œ ìœ„í—˜ ì‹œê·¸ë„ ê°ì§€**

**Neo4j Cypher (Production-Ready):**

```cypher
// ========================================
// Use Case 4: ìœ„í—˜ ì‹œê·¸ë„ ì¡°ê¸° ê°ì§€
// Input: candidate_id
// Output: AI_Recommendation
// ========================================

// Step 1: í›„ë³´ì Aì˜ ìŠ¤í‚¬ í”„ë¡œí•„ ì¶”ì¶œ
MATCH (candidateA:Candidate {id: $candidate_id})-[has:HAS_SKILL]->(skill:Skill)
WITH candidateA, COLLECT({
  skill_id: skill.id,
  skill_name: skill.canonical_name,
  proficiency: has.proficiency_level,
  weight: CASE has.proficiency_level
    WHEN 'beginner' THEN 1.0
    WHEN 'intermediate' THEN 2.0
    WHEN 'advanced' THEN 3.0
    WHEN 'expert' THEN 4.0
    ELSE 1.0
  END
}) AS skills_a

// Step 2: ìœ ì‚¬í•œ í”„ë¡œí•„ì„ ê°€ì§„ í›„ë³´ì ì°¾ê¸° (SIMILAR_TO íŒŒìƒ Link)
MATCH (similar:Candidate)-[has_sim:HAS_SKILL]->(skill:Skill)
WHERE similar <> candidateA
  AND skill.id IN [s IN skills_a | s.skill_id]
WITH
  candidateA,
  skills_a,
  similar,
  COLLECT({
    skill_id: skill.id,
    proficiency: has_sim.proficiency_level,
    weight: CASE has_sim.proficiency_level
      WHEN 'beginner' THEN 1.0
      WHEN 'intermediate' THEN 2.0
      WHEN 'advanced' THEN 3.0
      WHEN 'expert' THEN 4.0
      ELSE 1.0
    END
  }) AS skills_b

// Step 3: Weighted Jaccard Similarity ê³„ì‚°
WITH
  candidateA,
  similar,
  skills_a,
  skills_b,
  // Intersection
  REDUCE(sum = 0.0, s IN skills_a |
    sum + CASE
      WHEN ANY(sb IN skills_b WHERE sb.skill_id = s.skill_id)
      THEN REDUCE(min_w = 0.0, sb IN skills_b |
        CASE WHEN sb.skill_id = s.skill_id THEN
          CASE WHEN s.weight < sb.weight THEN s.weight ELSE sb.weight END
        ELSE min_w END
      )
      ELSE 0.0
    END
  ) AS intersection,
  // Union
  REDUCE(sum = 0.0, s IN (skills_a + skills_b) | sum + s.weight) AS union_weight
WITH
  candidateA,
  similar,
  intersection / union_weight AS similarity
WHERE similarity >= 0.5  // Threshold

// Step 4: ìœ ì‚¬ í›„ë³´ìì˜ ìµœì¢… ë‹¨ê³„ íƒˆë½ ì´ë ¥ ì¡°íšŒ
MATCH (similar)-[:CREATES]->(app:Application)
      -[:PROGRESSES_TO]->(st:StageTransition)
WHERE st.to_stage IN ['rejected', 'withdrawn']
  AND st.from_stage IN ['final_interview', 'offer', 'reference_check']
  AND st.actual_timestamp > datetime() - duration({months: 12})

// Step 5: í‰ê°€ í”¼ë“œë°± ìˆ˜ì§‘
OPTIONAL MATCH (app)-[:SCHEDULES]->(interview:Interview)
               -[:EVALUATES]->(eval:Evaluation)
WITH
  candidateA,
  COLLECT(DISTINCT similar) AS risk_candidates,
  COLLECT(DISTINCT {
    candidate_id: similar.id,
    candidate_name: similar.name,
    similarity_score: similarity,
    rejection_stage: st.from_stage,
    rejection_date: st.actual_timestamp,
    feedback: eval.feedback_text
  }) AS risk_details
WHERE SIZE(risk_candidates) >= 3  // ìµœì†Œ 3ëª… ì´ìƒ íŒ¨í„´

// Step 6: AI_Recommendation ìƒì„±
CREATE (rec:AI_Recommendation {
  recommendation_id: apoc.create.uuid(),
  type: 'risk_signal',
  target_entity_type: 'Candidate',
  target_entity_id: candidateA.id,
  confidence_score: 0.75 + (SIZE(risk_candidates) - 3) * 0.05,  // 3ëª…: 0.75, 4ëª…: 0.80, ...
  reasoning: 'Found ' + SIZE(risk_candidates) + ' similar candidates who dropped out at final stages',
  suggested_action: 'Strengthen reference check and verify hands-on experience',
  created_at: datetime(),
  user_action: null,
  metadata: {
    risk_candidate_count: SIZE(risk_candidates),
    risk_details: risk_details
  }
})

// Step 7: Link ìƒì„±
CREATE (rec)-[:RECOMMENDS_FOR]->(candidateA)

RETURN rec, risk_details
```

**ì¶œë ¥ ì˜ˆì‹œ:**

```json
{
  "recommendation": {
    "recommendation_id": "rec_550e8400-e29b-41d4-a716-446655440000",
    "type": "risk_signal",
    "target_entity_id": "cand_A",
    "confidence_score": 0.85,
    "reasoning": "Found 5 similar candidates who dropped out at final stages",
    "suggested_action": "Strengthen reference check and verify hands-on experience",
    "created_at": "2026-01-07T10:30:00Z"
  },
  "risk_details": [
    {
      "candidate_id": "cand_B",
      "candidate_name": "ê¹€OO",
      "similarity_score": 0.72,
      "rejection_stage": "reference_check",
      "rejection_date": "2025-11-15T14:20:00Z",
      "feedback": "Previous employer reported inconsistent work history"
    },
    {
      "candidate_id": "cand_C",
      "candidate_name": "ì´OO",
      "similarity_score": 0.68,
      "rejection_stage": "final_interview",
      "rejection_date": "2025-10-20T09:45:00Z",
      "feedback": "Technical skills overstated in resume"
    },
    // ... 3 more
  ]
}
```

---

### 7.2 SIMILAR_TO ê³„ì‚° ì•Œê³ ë¦¬ì¦˜ ìƒì„¸

**ì•Œê³ ë¦¬ì¦˜ ìŠ¤í™ (Phase 1):**

```python
"""
Weighted Jaccard Similarity for Candidate Skill Profiles

Version: 1.0
Author: Forry (Ontology Architect)
Date: 2026-01-07

Algorithm:
  similarity(A, B) = Î£ min(weight_A[s], weight_B[s]) for s in (A âˆ© B)
                     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                     Î£ max(weight_A[s], weight_B[s]) for s in (A âˆª B)

Where:
  - weight[s] = proficiency_level_to_weight(proficiency)
  - proficiency_level_to_weight: beginner=1.0, intermediate=2.0, advanced=3.0, expert=4.0

Properties:
  - Range: [0.0, 1.0]
  - Symmetric: similarity(A, B) = similarity(B, A)
  - Reflexive: similarity(A, A) = 1.0
  - Triangle Inequality: ë§Œì¡±í•˜ì§€ ì•ŠìŒ (JaccardëŠ” metricì´ ì•„ë‹˜)

Complexity:
  - Time: O(|A| + |B|) where |A| = number of skills in A
  - Space: O(|A âˆª B|)
"""

from typing import Dict, List, Tuple

# Type Definitions
ProficiencyLevel = str  # "beginner" | "intermediate" | "advanced" | "expert"
SkillID = str
Skill = Tuple[SkillID, ProficiencyLevel]
SkillProfile = Dict[SkillID, ProficiencyLevel]

# Constants
PROFICIENCY_WEIGHTS = {
    'beginner': 1.0,
    'intermediate': 2.0,
    'advanced': 3.0,
    'expert': 4.0
}

def weighted_jaccard_similarity(
    profile_a: SkillProfile,
    profile_b: SkillProfile
) -> float:
    """
    Calculate Weighted Jaccard Similarity between two skill profiles.

    Args:
        profile_a: {skill_id: proficiency_level} for candidate A
        profile_b: {skill_id: proficiency_level} for candidate B

    Returns:
        Similarity score in [0.0, 1.0]

    Example:
        >>> profile_a = {'python': 'advanced', 'django': 'intermediate'}
        >>> profile_b = {'python': 'expert', 'flask': 'intermediate'}
        >>> weighted_jaccard_similarity(profile_a, profile_b)
        0.5  # (3.0) / (4.0 + 2.0)
    """
    if not profile_a or not profile_b:
        return 0.0

    # Get all skill IDs
    all_skills = set(profile_a.keys()) | set(profile_b.keys())
    common_skills = set(profile_a.keys()) & set(profile_b.keys())

    # Calculate intersection weight
    intersection_weight = 0.0
    for skill_id in common_skills:
        weight_a = PROFICIENCY_WEIGHTS.get(profile_a[skill_id], 1.0)
        weight_b = PROFICIENCY_WEIGHTS.get(profile_b[skill_id], 1.0)
        intersection_weight += min(weight_a, weight_b)

    # Calculate union weight
    union_weight = 0.0
    for skill_id in all_skills:
        weight_a = PROFICIENCY_WEIGHTS.get(profile_a.get(skill_id, 'beginner'), 1.0) if skill_id in profile_a else 0.0
        weight_b = PROFICIENCY_WEIGHTS.get(profile_b.get(skill_id, 'beginner'), 1.0) if skill_id in profile_b else 0.0
        union_weight += max(weight_a, weight_b)

    # Avoid division by zero
    if union_weight == 0.0:
        return 0.0

    similarity = intersection_weight / union_weight
    return round(similarity, 3)  # ì†Œìˆ˜ì  3ìë¦¬


def find_similar_candidates(
    target_candidate_id: str,
    all_candidates: List[Dict],
    threshold: float = 0.5,
    top_k: int = 10
) -> List[Dict]:
    """
    Find candidates similar to the target candidate.

    Args:
        target_candidate_id: ID of the target candidate
        all_candidates: List of all candidate objects with 'id' and 'skills' fields
        threshold: Minimum similarity score to be considered similar (default 0.5)
        top_k: Maximum number of similar candidates to return (default 10)

    Returns:
        List of dicts with 'candidate_id' and 'similarity' fields, sorted by similarity desc

    Example:
        >>> candidates = [
        ...     {'id': 'A', 'skills': {'python': 'advanced', 'django': 'intermediate'}},
        ...     {'id': 'B', 'skills': {'python': 'expert', 'django': 'advanced'}},
        ...     {'id': 'C', 'skills': {'java': 'advanced', 'spring': 'intermediate'}}
        ... ]
        >>> find_similar_candidates('A', candidates, threshold=0.5, top_k=5)
        [{'candidate_id': 'B', 'similarity': 0.857}]
    """
    # Find target candidate
    target_candidate = next((c for c in all_candidates if c['id'] == target_candidate_id), None)
    if not target_candidate:
        raise ValueError(f"Candidate {target_candidate_id} not found")

    target_skills = target_candidate.get('skills', {})

    # Calculate similarities
    similarities = []
    for candidate in all_candidates:
        if candidate['id'] == target_candidate_id:
            continue

        candidate_skills = candidate.get('skills', {})
        similarity = weighted_jaccard_similarity(target_skills, candidate_skills)

        if similarity >= threshold:
            similarities.append({
                'candidate_id': candidate['id'],
                'similarity': similarity
            })

    # Sort by similarity (descending) and return top K
    similarities.sort(key=lambda x: x['similarity'], reverse=True)
    return similarities[:top_k]


# Unit Tests
def test_weighted_jaccard_similarity():
    """Test cases for weighted_jaccard_similarity function"""

    # Test 1: Identical profiles
    profile_a = {'python': 'advanced', 'django': 'intermediate'}
    assert weighted_jaccard_similarity(profile_a, profile_a) == 1.0

    # Test 2: Completely different profiles
    profile_b = {'java': 'advanced', 'spring': 'intermediate'}
    assert weighted_jaccard_similarity(profile_a, profile_b) == 0.0

    # Test 3: Partial overlap
    profile_c = {'python': 'expert', 'django': 'beginner', 'react': 'intermediate'}
    # Intersection: min(3, 4) + min(2, 1) = 3 + 1 = 4
    # Union: max(3, 4) + max(2, 1) + max(0, 2) = 4 + 2 + 2 = 8
    # Similarity: 4 / 8 = 0.5
    assert weighted_jaccard_similarity(profile_a, profile_c) == 0.5

    # Test 4: Empty profiles
    assert weighted_jaccard_similarity({}, profile_a) == 0.0
    assert weighted_jaccard_similarity({}, {}) == 0.0

    print("âœ… All tests passed!")


if __name__ == '__main__':
    test_weighted_jaccard_similarity()
```

**ì•Œê³ ë¦¬ì¦˜ ê²€ì¦:**

```python
# Real-world example
profile_candidate_a = {
    'python': 'advanced',
    'django': 'advanced',
    'postgresql': 'intermediate',
    'docker': 'beginner'
}

profile_candidate_b = {
    'python': 'expert',
    'django': 'intermediate',
    'mysql': 'intermediate',
    'kubernetes': 'beginner'
}

similarity = weighted_jaccard_similarity(profile_candidate_a, profile_candidate_b)
print(f"Similarity: {similarity}")
# Output: 0.455

# Breakdown:
# Intersection:
#   python: min(3, 4) = 3
#   django: min(3, 2) = 2
#   Total: 5
# Union:
#   python: max(3, 4) = 4
#   django: max(3, 2) = 3
#   postgresql: max(2, 0) = 2
#   docker: max(1, 0) = 1
#   mysql: max(0, 2) = 2
#   kubernetes: max(0, 1) = 1
#   Total: 13
# Similarity: 5 / 13 = 0.385 (ì‹¤ì œ ê³„ì‚°ê³¼ ì•½ê°„ ì°¨ì´ëŠ” ë°˜ì˜¬ë¦¼)
```

---

### 7.3 ë°ì´í„° ìŠ¤í‚¤ë§ˆ v1.0 (Skill Object í¬í•¨)

**Complete Ontology Schema for Use Case 4**

```yaml
# ========================================
# ATS Ontology Schema v1.0
# Use Case: ìœ„í—˜ ì‹œê·¸ë„ ì¡°ê¸° ê°ì§€ (Risk Signal Detection)
# Date: 2026-01-07
# Author: Forry (Ontology Architect)
# ========================================

ontology_version: "1.0"
domain: "Applicant Tracking System (ATS)"
scope: "MVP Phase 2 - Skill-based similarity and risk detection"

# ========================================
# Object Types
# ========================================

objects:

  # --------------------------------------------------
  # Tier 1: Core Domain Objects
  # --------------------------------------------------

  - name: Candidate
    description: "ì±„ìš© ì§€ì›ì ê°œì¸"
    tier: 1
    properties:
      candidate_id:
        type: string
        required: true
        indexed: true
        description: "Unique identifier"
      name:
        type: string
        required: true
      email:
        type: string
        required: true
        validation: email_format
      phone:
        type: string
        required: false
      applied_date:
        type: datetime
        required: true
      current_status:
        type: enum
        values: ["active", "withdrawn", "hired", "rejected"]
        default: "active"
      linkedin_url:
        type: string
        required: false
      resume_url:
        type: string
        required: false
      created_at:
        type: datetime
        auto_generated: true
      updated_at:
        type: datetime
        auto_updated: true

  - name: JobPosting
    description: "ì±„ìš© ê³µê³ "
    tier: 1
    properties:
      job_id:
        type: string
        required: true
        indexed: true
      title:
        type: string
        required: true
      department:
        type: string
        required: true
      employment_type:
        type: enum
        values: ["full_time", "part_time", "contract", "intern"]
      salary_range:
        type: object
        schema:
          min: number
          max: number
          currency: string
      posted_date:
        type: datetime
        required: true
      closing_date:
        type: datetime
        required: false
      status:
        type: enum
        values: ["open", "closed", "on_hold"]
        default: "open"

  - name: Application
    description: "íŠ¹ì • ê³µê³ ì— ëŒ€í•œ ì§€ì›"
    tier: 1
    properties:
      application_id:
        type: string
        required: true
        indexed: true
      applied_date:
        type: datetime
        required: true
      source_channel:
        type: enum
        values: ["website", "referral", "linkedin", "job_board", "other"]
      resume_url:
        type: string
        required: false
      cover_letter:
        type: text
        required: false
      current_stage:
        type: string
        required: true
        indexed: true
      current_stage_entered_at:
        type: datetime
        required: true
      overall_status:
        type: enum
        values: ["active", "rejected", "withdrawn", "hired"]
        default: "active"

  - name: Interview
    description: "ë©´ì ‘ ì´ë²¤íŠ¸"
    tier: 1
    properties:
      interview_id:
        type: string
        required: true
        indexed: true
      scheduled_date:
        type: datetime
        required: true
      actual_date:
        type: datetime
        required: false
      completion_status:
        type: enum
        values: ["scheduled", "completed", "cancelled", "no_show"]
        default: "scheduled"
      type:
        type: enum
        values: ["phone", "video", "onsite", "panel"]
      duration_minutes:
        type: number
        required: false
      location:
        type: string
        required: false
      meeting_link:
        type: string
        required: false

  - name: Evaluation
    description: "í‰ê°€ ê¸°ë¡"
    tier: 1
    properties:
      evaluation_id:
        type: string
        required: true
        indexed: true
      score:
        type: number
        required: true
        validation: "range(1, 5)"
      rubric_used:
        type: string
        required: false
      feedback_text:
        type: text
        required: false
      strengths:
        type: array
        items: string
      concerns:
        type: array
        items: string
      recommendation:
        type: enum
        values: ["strong_yes", "yes", "maybe", "no", "strong_no"]
      created_at:
        type: datetime
        auto_generated: true

  # --------------------------------------------------
  # Tier 2: Process Management Objects
  # --------------------------------------------------

  - name: RecruitmentStage
    description: "ì±„ìš© ë‹¨ê³„ ì •ì˜"
    tier: 2
    properties:
      stage_id:
        type: string
        required: true
        indexed: true
      stage_name:
        type: string
        required: true
        indexed: true
      sequence_order:
        type: number
        required: true
        description: "Stage order in the recruitment process (1, 2, 3, ...)"
      average_duration_days:
        type: number
        required: false
        description: "Benchmark duration for this stage"
      pass_rate:
        type: number
        required: false
        validation: "range(0, 1)"
        description: "Historical pass rate (0.0 - 1.0)"

  - name: StageTransition
    description: "ë‹¨ê³„ ì´ë™ ì´ë²¤íŠ¸"
    tier: 2
    properties:
      transition_id:
        type: string
        required: true
        indexed: true
      application_id:
        type: string
        required: true
        indexed: true
      from_stage:
        type: string
        required: true
        indexed: true
      to_stage:
        type: string
        required: true
        indexed: true
      scheduled_timestamp:
        type: datetime
        required: false
        description: "Planned transition time"
      actual_timestamp:
        type: datetime
        required: true
        indexed: true
        description: "Actual transition time"
      duration_in_prev_stage_hours:
        type: number
        required: false
      triggered_by:
        type: string
        required: false
        description: "User ID who triggered the transition"
      completion_status:
        type: enum
        values: ["completed", "scheduled", "cancelled"]
        default: "completed"
      notes:
        type: text
        required: false

  # --------------------------------------------------
  # Tier 3: AI & Intelligence Objects
  # --------------------------------------------------

  - name: AI_Recommendation
    description: "AI ë¶„ì„ ë° ì¶”ì²œ ê¸°ë¡"
    tier: 3
    properties:
      recommendation_id:
        type: string
        required: true
        indexed: true
      type:
        type: enum
        values: ["risk_signal", "bottleneck_alert", "similar_candidate", "communication_quality"]
        required: true
        indexed: true
      target_entity_type:
        type: enum
        values: ["Candidate", "Application", "JobPosting"]
        required: true
      target_entity_id:
        type: string
        required: true
        indexed: true
      confidence_score:
        type: number
        required: true
        validation: "range(0, 1)"
        description: "AI confidence (0.0 - 1.0)"
      reasoning:
        type: text
        required: true
        description: "Human-readable explanation of the recommendation"
      suggested_action:
        type: string
        required: false
      created_at:
        type: datetime
        auto_generated: true
        indexed: true
      user_action:
        type: enum
        values: ["accepted", "rejected", "ignored", null]
        default: null
        description: "User response to the recommendation"
      user_action_timestamp:
        type: datetime
        required: false
      rejection_reason:
        type: string
        required: false
        description: "Why user rejected the recommendation"
      feedback_text:
        type: text
        required: false
      metadata:
        type: jsonb
        required: false
        description: "Additional context (e.g., risk_details, similar_candidate_ids)"

  # --------------------------------------------------
  # Tier 4: Reference Data Objects
  # --------------------------------------------------

  - name: Skill
    description: "ìŠ¤í‚¬/ì—­ëŸ‰ (í‘œì¤€í™”ëœ)"
    tier: 4
    properties:
      skill_id:
        type: string
        required: true
        indexed: true
        description: "Unique skill identifier (e.g., skill_python_001)"
      canonical_name:
        type: string
        required: true
        indexed: true
        unique: true
        description: "Normalized skill name (e.g., 'Python')"
      synonyms:
        type: array
        items: string
        description: "List of synonyms (e.g., ['python', 'Python3', 'íŒŒì´ì¬'])"
      tier:
        type: number
        required: true
        validation: "range(1, 3)"
        description: "Skill hierarchy tier (1=Domain, 2=Category, 3=Skill)"
      parent_skill_id:
        type: string
        required: false
        indexed: true
        description: "Parent skill ID (for hierarchy)"
      category:
        type: enum
        values: ["technical", "soft", "domain", "industry"]
        required: true
      proficiency_levels:
        type: array
        items: string
        default: ["beginner", "intermediate", "advanced", "expert"]
      description:
        type: text
        required: false
      external_ids:
        type: jsonb
        required: false
        description: "External skill taxonomy mappings (e.g., LinkedIn, O*NET)"
      created_at:
        type: datetime
        auto_generated: true

# ========================================
# Link Types (Relationships)
# ========================================

links:

  # --------------------------------------------------
  # Static Relationships
  # --------------------------------------------------

  - name: APPLIES_TO
    from: Candidate
    to: JobPosting
    reverse: HAS_APPLICANT
    cardinality: "N:M"
    description: "í›„ë³´ìê°€ ê³µê³ ì— ì§€ì›í•¨"
    properties: {}

  - name: CREATES
    from: Application
    to: Candidate
    reverse: CREATED_BY
    cardinality: "N:1"
    description: "ì§€ì›ì„œê°€ íŠ¹ì • í›„ë³´ìê°€ ì œì¶œí•¨"
    properties: {}

  - name: FOR_POSITION
    from: Application
    to: JobPosting
    reverse: HAS_APPLICATION
    cardinality: "N:1"
    description: "ì§€ì›ì„œê°€ íŠ¹ì • ê³µê³ ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•¨"
    properties: {}

  - name: SCHEDULES
    from: Interview
    to: Application
    reverse: HAS_INTERVIEW
    cardinality: "N:1"
    description: "ë©´ì ‘ì´ íŠ¹ì • ì§€ì› ê±´ì— ì†í•¨"
    properties: {}

  - name: EVALUATES
    from: Evaluation
    to: Interview
    reverse: HAS_EVALUATION
    cardinality: "N:1"
    description: "í‰ê°€ê°€ íŠ¹ì • ë©´ì ‘ì— ëŒ€í•œ ê²ƒì„"
    properties: {}

  # --------------------------------------------------
  # Dynamic Relationships
  # --------------------------------------------------

  - name: PROGRESSES_TO
    from: StageTransition
    to: RecruitmentStage
    reverse: RECEIVES_FROM
    cardinality: "N:1"
    description: "ë‹¨ê³„ ì „í™˜ì´ íŠ¹ì • ë‹¨ê³„ë¡œ ì§„í–‰"
    properties:
      timestamp:
        type: datetime
        required: true
      duration_in_prev_stage:
        type: number
        required: false

  - name: RECOMMENDS_FOR
    from: AI_Recommendation
    to: [Candidate, Application, JobPosting]
    reverse: HAS_RECOMMENDATION
    cardinality: "N:1"
    description: "AI ì¶”ì²œì´ íŠ¹ì • ì—”í‹°í‹°ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•¨"
    properties:
      relevance_score:
        type: number
        required: false
        validation: "range(0, 1)"

  # --------------------------------------------------
  # Skill-Related Relationships
  # --------------------------------------------------

  - name: HAS_SKILL
    from: Candidate
    to: Skill
    reverse: POSSESSED_BY
    cardinality: "N:M"
    description: "í›„ë³´ìê°€ ìŠ¤í‚¬ì„ ë³´ìœ í•¨"
    properties:
      proficiency_level:
        type: enum
        values: ["beginner", "intermediate", "advanced", "expert"]
        required: true
      years_of_experience:
        type: number
        required: false
      verified:
        type: boolean
        default: false
        description: "ì‹¤ì œ ê²€ì¦ ì—¬ë¶€ (ë©´ì ‘ ë˜ëŠ” í…ŒìŠ¤íŠ¸)"
      source:
        type: enum
        values: ["resume", "interview", "test", "manual_input", "inferred_from_job_posting"]
        required: true
      extraction_confidence:
        type: number
        required: false
        validation: "range(0, 1)"
        description: "LLM ì¶”ì¶œ ì‹ ë¢°ë„ (0.0 - 1.0)"
      created_at:
        type: datetime
        auto_generated: true

  - name: REQUIRES_SKILL
    from: JobPosting
    to: Skill
    reverse: REQUIRED_BY
    cardinality: "N:M"
    description: "ê³µê³ ê°€ íŠ¹ì • ìŠ¤í‚¬ì„ ìš”êµ¬í•¨"
    properties:
      required_level:
        type: enum
        values: ["beginner", "intermediate", "advanced", "expert"]
        required: true
      is_mandatory:
        type: boolean
        default: true
        description: "í•„ìˆ˜ vs ìš°ëŒ€ ìŠ¤í‚¬"
      priority:
        type: number
        required: false
        validation: "range(1, 10)"
        description: "ìŠ¤í‚¬ ìš°ì„ ìˆœìœ„ (1=ê°€ì¥ ì¤‘ìš”)"

  - name: BELONGS_TO
    from: Skill
    to: Skill
    reverse: HAS_CHILD_SKILL
    cardinality: "N:1"
    description: "ìŠ¤í‚¬ì´ ìƒìœ„ ì¹´í…Œê³ ë¦¬ì— ì†í•¨ (ê³„ì¸µ êµ¬ì¡°)"
    properties:
      inheritance_type:
        type: enum
        values: ["is_a", "part_of"]
        default: "is_a"
        description: "ê´€ê³„ íƒ€ì… (e.g., Python IS_A Backend Development)"

  - name: RELATED_TO
    from: Skill
    to: Skill
    reverse: RELATED_TO
    cardinality: "N:M"
    description: "ìŠ¤í‚¬ ê°„ ì—°ê´€ ê´€ê³„"
    properties:
      relationship_type:
        type: enum
        values: ["complementary", "prerequisite", "alternative"]
        required: true
        description: "ì—°ê´€ íƒ€ì… (ì˜ˆ: Django COMPLEMENTARY Python)"
      co_occurrence_rate:
        type: number
        required: false
        validation: "range(0, 1)"
        description: "í•¨ê»˜ ë‚˜íƒ€ë‚˜ëŠ” ë¹„ìœ¨ (0.0 - 1.0)"

  # --------------------------------------------------
  # Derived Relationships (ê³„ì‚°ë¨)
  # --------------------------------------------------

  - name: SIMILAR_TO
    from: Candidate
    to: Candidate
    reverse: SIMILAR_TO
    cardinality: "N:M"
    description: "í›„ë³´ì ê°„ ìœ ì‚¬ë„ (íŒŒìƒ Link, ìë™ ê³„ì‚°)"
    derived: true
    calculation_method: "weighted_jaccard_similarity"
    properties:
      similarity_score:
        type: number
        required: true
        validation: "range(0, 1)"
        indexed: true
      matching_skills:
        type: array
        items: string
        description: "ê³µí†µ ìŠ¤í‚¬ ID ëª©ë¡"
      calculation_method:
        type: enum
        values: ["skill_overlap", "ml_embedding"]
        default: "skill_overlap"
      calculated_at:
        type: datetime
        auto_generated: true
        description: "ë§ˆì§€ë§‰ ê³„ì‚° ì‹œì "
      recalculation_needed:
        type: boolean
        default: false
        description: "ìŠ¤í‚¬ ë³€ê²½ ì‹œ trueë¡œ ì„¤ì •"

# ========================================
# Validation Rules
# ========================================

validation_rules:

  - name: candidate_email_unique
    object: Candidate
    rule: "email must be unique across all candidates"

  - name: skill_canonical_name_unique
    object: Skill
    rule: "canonical_name must be unique across all skills"

  - name: application_must_have_candidate
    link: CREATES
    rule: "Every Application must be linked to exactly one Candidate"

  - name: stagetransition_temporal_consistency
    object: StageTransition
    rule: "actual_timestamp must be >= scheduled_timestamp (if scheduled_timestamp exists)"

  - name: evaluation_score_range
    object: Evaluation
    rule: "score must be between 1 and 5"

  - name: similarity_threshold_enforcement
    link: SIMILAR_TO
    rule: "similarity_score must be >= 0.5 to create link (threshold can be adjusted)"

  - name: ai_recommendation_confidence_range
    object: AI_Recommendation
    rule: "confidence_score must be between 0.0 and 1.0"

  - name: has_skill_proficiency_required
    link: HAS_SKILL
    rule: "proficiency_level is required when linking Candidate to Skill"

# ========================================
# Indexing Strategy
# ========================================

indexes:

  # Object Indexes
  - object: Candidate
    fields: [candidate_id, email, current_status]
    type: btree

  - object: Application
    fields: [application_id, current_stage, current_stage_entered_at]
    type: btree

  - object: StageTransition
    fields: [application_id, from_stage, to_stage, actual_timestamp]
    type: btree

  - object: Skill
    fields: [skill_id, canonical_name]
    type: btree

  - object: Skill
    fields: [synonyms]
    type: gin
    description: "Array index for synonym matching"

  - object: AI_Recommendation
    fields: [target_entity_id, type, created_at]
    type: btree

  # Link Indexes
  - link: HAS_SKILL
    fields: [candidate_id, skill_id, proficiency_level]
    type: composite

  - link: SIMILAR_TO
    fields: [similarity_score]
    type: btree
    order: desc

  # Full-text Indexes
  - object: Evaluation
    fields: [feedback_text]
    type: fulltext

  - object: Skill
    fields: [canonical_name, synonyms]
    type: fulltext

# ========================================
# Data Quality Metrics
# ========================================

quality_metrics:

  - name: candidate_skill_coverage
    description: "í›„ë³´ìë‹¹ í‰ê·  ìŠ¤í‚¬ ìˆ˜"
    target: "5-10 skills per candidate"
    measurement: "AVG(COUNT(HAS_SKILL per candidate))"

  - name: skill_extraction_confidence
    description: "LLM ì¶”ì¶œ ì‹ ë¢°ë„"
    target: ">= 70% of skills with confidence >= 0.7"
    measurement: "COUNT(HAS_SKILL WHERE extraction_confidence >= 0.7) / COUNT(HAS_SKILL)"

  - name: skill_verification_rate
    description: "ê²€ì¦ëœ ìŠ¤í‚¬ ë¹„ìœ¨"
    target: ">= 30% of skills verified"
    measurement: "COUNT(HAS_SKILL WHERE verified = true) / COUNT(HAS_SKILL)"

  - name: ai_recommendation_acceptance_rate
    description: "AI ì¶”ì²œ ìˆ˜ë½ë¥ "
    target: "60-70%"
    measurement: "COUNT(AI_Recommendation WHERE user_action = 'accepted') / COUNT(AI_Recommendation)"

  - name: similar_to_recalculation_lag
    description: "ìœ ì‚¬ë„ ì¬ê³„ì‚° ì§€ì—°"
    target: "< 7 days"
    measurement: "AVG(NOW() - SIMILAR_TO.calculated_at WHERE recalculation_needed = true)"

# ========================================
# Migration Strategy
# ========================================

migration:

  phase: "Phase 2 (MVP + 4 months)"

  steps:

    1_skill_taxonomy_creation:
      description: "Create initial Skill taxonomy (30 skills)"
      duration: "2 weeks"
      owner: "PM + Ontology Architect"
      deliverables:
        - "Skill hierarchy (3 tiers)"
        - "Synonym mapping (100+ entries)"
        - "External ID mapping (LinkedIn, O*NET)"

    2_resume_data_extraction:
      description: "Extract skills from existing resumes (500 candidates)"
      duration: "3 weeks"
      owner: "Dev Team + Data Analyst"
      tools:
        - "OpenAI GPT-4 API (Batch)"
        - "Custom normalization pipeline"
      expected_cost: "$20-30 (LLM API)"

    3_has_skill_link_creation:
      description: "Create HAS_SKILL links for all candidates"
      duration: "1 week"
      owner: "Dev Team"
      data_quality_target: "70% confidence threshold"

    4_similar_to_calculation:
      description: "Calculate SIMILAR_TO links (initial batch)"
      duration: "1 week"
      owner: "Dev Team"
      algorithm: "weighted_jaccard_similarity (threshold 0.5)"

    5_validation_study:
      description: "Human validation of similarity scores"
      duration: "2 weeks"
      owner: "PM + Recruiter Team"
      sample_size: "50 candidates Ã— 5 similar candidates = 250 pairs"
      target_precision: "70%"

    6_ai_recommendation_integration:
      description: "Integrate Use Case 4 into UI"
      duration: "2 weeks"
      owner: "Frontend Team"
      deliverables:
        - "Risk signal alert UI"
        - "User feedback collection"

# ========================================
# End of Schema
# ========================================
```

---

## 8. ìµœì¢… ê¶Œì¥ì‚¬í•­ ìš”ì•½

### 8.1 MVP ë²”ìœ„ ì¬ì¡°ì •

**âœ… ì¶”ì²œ: Use Case 1ë§Œ MVPì— í¬í•¨**

- **Objects**: Candidate, Application, StageTransition, RecruitmentStage, AI_Recommendation (5ê°œ)
- **ê°œë°œ ê¸°ê°„**: 8ì£¼
- **ì„±ê³µ ê¸°ì¤€**: ë³‘ëª© ì•Œë¦¼ ì •í™•ë„ Â±3ì¼, AI ì œì•ˆ ìˆ˜ë½ë¥  60%+

**â¸ï¸ Phase 2ë¡œ ì—°ê¸°: Use Case 2, 4**

- **Objects ì¶”ê°€**: Skill, Interview, Evaluation (3ê°œ)
- **ê°œë°œ ê¸°ê°„**: MVP + 4ê°œì›”
- **ì´ìœ **: Skill ë°ì´í„° í’ˆì§ˆ í™•ë³´ ì‹œê°„ í•„ìš”

---

### 8.2 Skill Object ì„¤ê³„ ìš°ì„  ì™„ë£Œ

**Phase 1.5 (MVPì™€ Phase 2 ì‚¬ì´, 2ê°œì›”):**

1. **Skill Taxonomy ì •ì˜**
   - 30ê°œ í•µì‹¬ ìŠ¤í‚¬ (Backend, Frontend, Data Science)
   - 3-tier hierarchy (Domain â†’ Category â†’ Skill)
   - Synonym mapping (100+ entries)

2. **Normalization Pipeline êµ¬ì¶•**
   - LLM ê¸°ë°˜ ì¶”ì¶œ (GPT-4)
   - Rule-based validation
   - Human-in-the-loop for confidence < 0.7

3. **ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜**
   - 500ëª… ì´ë ¥ì„œì—ì„œ ìŠ¤í‚¬ ì¶”ì¶œ
   - HAS_SKILL Link ìƒì„±
   - í’ˆì§ˆ ê²€ì¦ (70% confidence target)

---

### 8.3 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë¨¼ì € ì‹¤í–‰

**Action Item (1ì£¼ Sprint):**

1. **ìƒ˜í”Œ ë°ì´í„° ìƒì„±**
   - 1,000ëª… í›„ë³´ì (synthetic data)
   - í‰ê·  10ê°œ ìŠ¤í‚¬/í›„ë³´ì
   - 500ê°œ ì§€ì› ì´ë ¥

2. **PostgreSQL vs Neo4j ë¹„êµ**
   - Use Case 4 ì¿¼ë¦¬ ì‹¤í–‰
   - ì„±ëŠ¥ ì¸¡ì • (10íšŒ í‰ê· )
   - ê²°ê³¼ ë¦¬í¬íŠ¸ ì‘ì„±

3. **ëª©í‘œ ê²€ì¦**
   - "5ë°° ì´ìƒ ë¹ ë¦„" ì¦ëª…
   - ì‹¤ì œë¡œ ë‹¬ì„± ëª»í•˜ë©´ MVP ë²”ìœ„ ì¬ì¡°ì •

---

### 8.4 AI ì² í•™ ì¤€ìˆ˜ ì²´í¬

**ëª¨ë“  Use Caseì— ëŒ€í•´:**

- [ ] íˆ¬ëª…ì„±: ê·¼ê±° 3ì¤„ ì´ë‚´ ì„¤ëª… ê°€ëŠ¥
- [ ] ì˜¤ë²„ë¼ì´ë“œ: "ë¬´ì‹œí•˜ê¸°" ë²„íŠ¼ ëª…í™•
- [ ] í•™ìŠµ ë£¨í”„: user_action í•„ë“œ ê¸°ë¡
- [ ] ëª…ëª…: "ìë™" ëŒ€ì‹  "ë¶„ì„", "ì•Œë¦¼" ì‚¬ìš©
- [ ] ìµœì¢… ê²°ì •ê¶Œ: AI ì—†ì´ë„ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ê°€ëŠ¥

---

## 9. Next Steps (Immediate Actions)

**Week 1:**
- [ ] Terry: MVP ë²”ìœ„ ì¬ì¡°ì • ìŠ¹ì¸ (Use Case 1ë§Œ vs 1+2+4)
- [ ] Forry: Skill Taxonomy v0.1 ì´ˆì•ˆ ì‘ì„± (30ê°œ ìŠ¤í‚¬)
- [ ] Dev Team: PostgreSQL vs Neo4j ë²¤ì¹˜ë§ˆí¬ í™˜ê²½ êµ¬ì¶•

**Week 2:**
- [ ] ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ë° ê²°ê³¼ ë¦¬í¬íŠ¸
- [ ] Skill Normalization Pipeline ì„¤ê³„
- [ ] Phase 1.5 ê³„íš ìˆ˜ë¦½ (Skill ë°ì´í„° êµ¬ì¶•)

**Week 3-4:**
- [ ] MVP ê°œë°œ ì‹œì‘ (Use Case 1)
- [ ] Skill Taxonomy ì™„ì„± (Synonym mapping í¬í•¨)
- [ ] LLM ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ í”„ë¡œí† íƒ€ì…

---

**ë¬¸ì„œ ë**

ì´ ê²€ì¦ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ Terryì™€ ê°œë°œíŒ€ì´ MVP ë²”ìœ„ë¥¼ ìµœì¢… ê²°ì •í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
